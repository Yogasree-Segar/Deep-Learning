{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "attdata = pd.read_csv('att.csv',delim_whitespace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = pd.read_csv('communities.data',names = attdata['attributes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 128)\n"
     ]
    }
   ],
   "source": [
    "print(comm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>community</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>81440</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>95</td>\n",
       "      <td>6096</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state county community        communityname  fold  population  \\\n",
       "0      8      ?         ?         Lakewoodcity     1        0.19   \n",
       "1     53      ?         ?          Tukwilacity     1        0.00   \n",
       "2     24      ?         ?         Aberdeentown     1        0.00   \n",
       "3     34      5     81440  Willingborotownship     1        0.04   \n",
       "4     42     95      6096    Bethlehemtownship     1        0.01   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian  ...  LandArea  \\\n",
       "0           0.33          0.02          0.90          0.12  ...      0.12   \n",
       "1           0.16          0.12          0.74          0.45  ...      0.02   \n",
       "2           0.42          0.49          0.56          0.17  ...      0.01   \n",
       "3           0.77          1.00          0.08          0.12  ...      0.02   \n",
       "4           0.55          0.02          0.95          0.09  ...      0.04   \n",
       "\n",
       "   PopDens  PctUsePubTrans  PolicCars  PolicOperBudg  LemasPctPolicOnPatr  \\\n",
       "0     0.26            0.20       0.06           0.04                  0.9   \n",
       "1     0.12            0.45          ?              ?                    ?   \n",
       "2     0.21            0.02          ?              ?                    ?   \n",
       "3     0.39            0.28          ?              ?                    ?   \n",
       "4     0.09            0.02          ?              ?                    ?   \n",
       "\n",
       "   LemasGangUnitDeploy  LemasPctOfficDrugUn  PolicBudgPerPop  \\\n",
       "0                  0.5                 0.32             0.14   \n",
       "1                    ?                 0.00                ?   \n",
       "2                    ?                 0.00                ?   \n",
       "3                    ?                 0.00                ?   \n",
       "4                    ?                 0.00                ?   \n",
       "\n",
       "   ViolentCrimesPerPop  \n",
       "0                 0.20  \n",
       "1                 0.67  \n",
       "2                 0.43  \n",
       "3                 0.12  \n",
       "4                 0.03  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = comm.drop(columns = ['state','county','community','communityname','fold'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "comm = comm.replace('?',np.nan)\n",
    "feat_miss = comm.columns[comm.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 100)\n"
     ]
    }
   ],
   "source": [
    "comm = comm.dropna(axis=1)\n",
    "print(comm.shape)\n",
    "# commdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = commdata.iloc[:,0:100].values\n",
    "# y = commdata.iloc[:,100].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain,Xtest = train_test_split(comm,test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['population', 'householdsize', 'racepctblack', 'racePctWhite',\n",
      "       'racePctAsian', 'racePctHisp', 'agePct12t21', 'agePct12t29',\n",
      "       'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban', 'medIncome',\n",
      "       'pctWWage', 'pctWFarmSelf', 'pctWInvInc', 'pctWSocSec', 'pctWPubAsst',\n",
      "       'pctWRetire', 'medFamInc', 'perCapInc', 'whitePerCap', 'blackPerCap',\n",
      "       'indianPerCap', 'AsianPerCap', 'HispPerCap', 'NumUnderPov',\n",
      "       'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad', 'PctBSorMore',\n",
      "       'PctUnemployed', 'PctEmploy', 'PctEmplManu', 'PctEmplProfServ',\n",
      "       'PctOccupManu', 'PctOccupMgmtProf', 'MalePctDivorce', 'MalePctNevMarr',\n",
      "       'FemalePctDiv', 'TotalPctDiv', 'PersPerFam', 'PctFam2Par',\n",
      "       'PctKids2Par', 'PctYoungKids2Par', 'PctTeen2Par', 'PctWorkMomYoungKids',\n",
      "       'PctWorkMom', 'NumIlleg', 'PctIlleg', 'NumImmig', 'PctImmigRecent',\n",
      "       'PctImmigRec5', 'PctImmigRec8', 'PctImmigRec10', 'PctRecentImmig',\n",
      "       'PctRecImmig5', 'PctRecImmig8', 'PctRecImmig10', 'PctSpeakEnglOnly',\n",
      "       'PctNotSpeakEnglWell', 'PctLargHouseFam', 'PctLargHouseOccup',\n",
      "       'PersPerOccupHous', 'PersPerOwnOccHous', 'PersPerRentOccHous',\n",
      "       'PctPersOwnOccup', 'PctPersDenseHous', 'PctHousLess3BR', 'MedNumBR',\n",
      "       'HousVacant', 'PctHousOccup', 'PctHousOwnOcc', 'PctVacantBoarded',\n",
      "       'PctVacMore6Mos', 'MedYrHousBuilt', 'PctHousNoPhone', 'PctWOFullPlumb',\n",
      "       'OwnOccLowQuart', 'OwnOccMedVal', 'OwnOccHiQuart', 'RentLowQ',\n",
      "       'RentMedian', 'RentHighQ', 'MedRent', 'MedRentPctHousInc',\n",
      "       'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg', 'NumInShelters',\n",
      "       'NumStreet', 'PctForeignBorn', 'PctBornSameState', 'PctSameHouse85',\n",
      "       'PctSameCity85', 'PctSameState85', 'LandArea', 'PopDens',\n",
      "       'PctUsePubTrans', 'LemasPctOfficDrugUn', 'ViolentCrimesPerPop'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Xtest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466     0.28\n",
      "1373    0.39\n",
      "476     0.14\n",
      "1500    0.04\n",
      "1301    0.40\n",
      "        ... \n",
      "786     0.41\n",
      "222     0.36\n",
      "394     0.01\n",
      "770     0.52\n",
      "292     0.03\n",
      "Name: ViolentCrimesPerPop, Length: 1395, dtype: float64\n",
      "\n",
      "172     0.08\n",
      "1125    0.71\n",
      "1251    0.22\n",
      "471     0.05\n",
      "441     0.35\n",
      "        ... \n",
      "960     0.26\n",
      "663     0.63\n",
      "616     0.09\n",
      "1096    0.44\n",
      "887     0.02\n",
      "Name: ViolentCrimesPerPop, Length: 599, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Ytrain = Xtrain.pop(\"ViolentCrimesPerPop\")\n",
    "Ytest = Xtest.pop(\"ViolentCrimesPerPop\")\n",
    "print(Ytrain)\n",
    "print()\n",
    "print(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing\n",
    "\n",
    "#Xtrain,Xtest,Ytrain,Ytest\n",
    "\n",
    "x_mean = Xtrain.mean(axis=0)\n",
    "Xtrain -= x_mean\n",
    "x_std = Xtrain.std(axis=0)\n",
    "Xtrain /=x_std\n",
    "Xtest -= x_mean\n",
    "Xtest /= x_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    model=models.Sequential()\n",
    "    model.add(layers.Dense(90, activation='relu',input_shape=(Xtrain.shape[1],)))\n",
    "    model.add(layers.Dense(90,activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 1163 samples, validate on 232 samples\n",
      "Epoch 1/100\n",
      "1163/1163 [==============================] - 1s 737us/step - loss: 0.1124 - mae: 0.2418 - val_loss: 0.1128 - val_mae: 0.2627\n",
      "Epoch 2/100\n",
      "1163/1163 [==============================] - 0s 236us/step - loss: 0.0474 - mae: 0.1649 - val_loss: 0.0485 - val_mae: 0.1747\n",
      "Epoch 3/100\n",
      "1163/1163 [==============================] - 0s 259us/step - loss: 0.0341 - mae: 0.1380 - val_loss: 0.0532 - val_mae: 0.1692\n",
      "Epoch 4/100\n",
      "1163/1163 [==============================] - 0s 236us/step - loss: 0.0287 - mae: 0.1248 - val_loss: 0.0336 - val_mae: 0.1461\n",
      "Epoch 5/100\n",
      "1163/1163 [==============================] - 0s 233us/step - loss: 0.0235 - mae: 0.1151 - val_loss: 0.0357 - val_mae: 0.1479\n",
      "Epoch 6/100\n",
      "1163/1163 [==============================] - 0s 232us/step - loss: 0.0188 - mae: 0.1021 - val_loss: 0.0525 - val_mae: 0.1663\n",
      "Epoch 7/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0170 - mae: 0.0975 - val_loss: 0.0556 - val_mae: 0.1759\n",
      "Epoch 8/100\n",
      "1163/1163 [==============================] - 0s 243us/step - loss: 0.0148 - mae: 0.0907 - val_loss: 0.0347 - val_mae: 0.1341\n",
      "Epoch 9/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0135 - mae: 0.0878 - val_loss: 0.0422 - val_mae: 0.1583\n",
      "Epoch 10/100\n",
      "1163/1163 [==============================] - 0s 251us/step - loss: 0.0136 - mae: 0.0850 - val_loss: 0.0318 - val_mae: 0.1348\n",
      "Epoch 11/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0122 - mae: 0.0830 - val_loss: 0.0328 - val_mae: 0.1407\n",
      "Epoch 12/100\n",
      "1163/1163 [==============================] - 0s 239us/step - loss: 0.0111 - mae: 0.0786 - val_loss: 0.0515 - val_mae: 0.1721\n",
      "Epoch 13/100\n",
      "1163/1163 [==============================] - 0s 235us/step - loss: 0.0103 - mae: 0.0750 - val_loss: 0.0287 - val_mae: 0.1281\n",
      "Epoch 14/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0099 - mae: 0.0732 - val_loss: 0.0342 - val_mae: 0.1377\n",
      "Epoch 15/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0087 - mae: 0.0695 - val_loss: 0.0402 - val_mae: 0.1514\n",
      "Epoch 16/100\n",
      "1163/1163 [==============================] - 0s 249us/step - loss: 0.0076 - mae: 0.0652 - val_loss: 0.0312 - val_mae: 0.1378\n",
      "Epoch 17/100\n",
      "1163/1163 [==============================] - 0s 242us/step - loss: 0.0078 - mae: 0.0644 - val_loss: 0.0465 - val_mae: 0.1494\n",
      "Epoch 18/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0072 - mae: 0.0618 - val_loss: 0.0380 - val_mae: 0.1470\n",
      "Epoch 19/100\n",
      "1163/1163 [==============================] - 0s 240us/step - loss: 0.0065 - mae: 0.0593 - val_loss: 0.0517 - val_mae: 0.1651\n",
      "Epoch 20/100\n",
      "1163/1163 [==============================] - 0s 267us/step - loss: 0.0066 - mae: 0.0597 - val_loss: 0.0427 - val_mae: 0.1558\n",
      "Epoch 21/100\n",
      "1163/1163 [==============================] - 0s 312us/step - loss: 0.0069 - mae: 0.0600 - val_loss: 0.0276 - val_mae: 0.1278\n",
      "Epoch 22/100\n",
      "1163/1163 [==============================] - 0s 280us/step - loss: 0.0054 - mae: 0.0556 - val_loss: 0.0295 - val_mae: 0.1277\n",
      "Epoch 23/100\n",
      "1163/1163 [==============================] - 0s 300us/step - loss: 0.0057 - mae: 0.0554 - val_loss: 0.0303 - val_mae: 0.1314\n",
      "Epoch 24/100\n",
      "1163/1163 [==============================] - 0s 301us/step - loss: 0.0056 - mae: 0.0539 - val_loss: 0.0319 - val_mae: 0.1389\n",
      "Epoch 25/100\n",
      "1163/1163 [==============================] - 0s 283us/step - loss: 0.0051 - mae: 0.0522 - val_loss: 0.0299 - val_mae: 0.1283\n",
      "Epoch 26/100\n",
      "1163/1163 [==============================] - 0s 263us/step - loss: 0.0050 - mae: 0.0515 - val_loss: 0.0293 - val_mae: 0.1290\n",
      "Epoch 27/100\n",
      "1163/1163 [==============================] - 0s 306us/step - loss: 0.0045 - mae: 0.0506 - val_loss: 0.0281 - val_mae: 0.1242\n",
      "Epoch 28/100\n",
      "1163/1163 [==============================] - 0s 289us/step - loss: 0.0050 - mae: 0.0502 - val_loss: 0.0294 - val_mae: 0.1252\n",
      "Epoch 29/100\n",
      "1163/1163 [==============================] - 0s 283us/step - loss: 0.0042 - mae: 0.0470 - val_loss: 0.0288 - val_mae: 0.1245\n",
      "Epoch 30/100\n",
      "1163/1163 [==============================] - 0s 261us/step - loss: 0.0039 - mae: 0.0455 - val_loss: 0.0328 - val_mae: 0.1392\n",
      "Epoch 31/100\n",
      "1163/1163 [==============================] - 0s 262us/step - loss: 0.0042 - mae: 0.0479 - val_loss: 0.0277 - val_mae: 0.1237\n",
      "Epoch 32/100\n",
      "1163/1163 [==============================] - 0s 241us/step - loss: 0.0037 - mae: 0.0451 - val_loss: 0.0271 - val_mae: 0.1216\n",
      "Epoch 33/100\n",
      "1163/1163 [==============================] - 0s 262us/step - loss: 0.0038 - mae: 0.0455 - val_loss: 0.0255 - val_mae: 0.1174\n",
      "Epoch 34/100\n",
      "1163/1163 [==============================] - 0s 263us/step - loss: 0.0039 - mae: 0.0456 - val_loss: 0.0310 - val_mae: 0.1323\n",
      "Epoch 35/100\n",
      "1163/1163 [==============================] - 0s 288us/step - loss: 0.0035 - mae: 0.0429 - val_loss: 0.0283 - val_mae: 0.1247\n",
      "Epoch 36/100\n",
      "1163/1163 [==============================] - 0s 265us/step - loss: 0.0033 - mae: 0.0423 - val_loss: 0.0250 - val_mae: 0.1177\n",
      "Epoch 37/100\n",
      "1163/1163 [==============================] - 0s 277us/step - loss: 0.0033 - mae: 0.0425 - val_loss: 0.0293 - val_mae: 0.1299\n",
      "Epoch 38/100\n",
      "1163/1163 [==============================] - 0s 242us/step - loss: 0.0031 - mae: 0.0423 - val_loss: 0.0287 - val_mae: 0.1308\n",
      "Epoch 39/100\n",
      "1163/1163 [==============================] - 0s 274us/step - loss: 0.0031 - mae: 0.0409 - val_loss: 0.0269 - val_mae: 0.1223\n",
      "Epoch 40/100\n",
      "1163/1163 [==============================] - 0s 263us/step - loss: 0.0031 - mae: 0.0402 - val_loss: 0.0280 - val_mae: 0.1265\n",
      "Epoch 41/100\n",
      "1163/1163 [==============================] - 0s 275us/step - loss: 0.0033 - mae: 0.0413 - val_loss: 0.0260 - val_mae: 0.1198\n",
      "Epoch 42/100\n",
      "1163/1163 [==============================] - 0s 270us/step - loss: 0.0027 - mae: 0.0382 - val_loss: 0.0264 - val_mae: 0.1210\n",
      "Epoch 43/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0031 - mae: 0.0396 - val_loss: 0.0269 - val_mae: 0.1227\n",
      "Epoch 44/100\n",
      "1163/1163 [==============================] - 0s 293us/step - loss: 0.0027 - mae: 0.0380 - val_loss: 0.0258 - val_mae: 0.1181\n",
      "Epoch 45/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0025 - mae: 0.0353 - val_loss: 0.0295 - val_mae: 0.1269\n",
      "Epoch 46/100\n",
      "1163/1163 [==============================] - 0s 265us/step - loss: 0.0025 - mae: 0.0354 - val_loss: 0.0305 - val_mae: 0.1298\n",
      "Epoch 47/100\n",
      "1163/1163 [==============================] - 0s 273us/step - loss: 0.0025 - mae: 0.0359 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 48/100\n",
      "1163/1163 [==============================] - 0s 290us/step - loss: 0.0028 - mae: 0.0380 - val_loss: 0.0346 - val_mae: 0.1333\n",
      "Epoch 49/100\n",
      "1163/1163 [==============================] - 0s 275us/step - loss: 0.0025 - mae: 0.0352 - val_loss: 0.0260 - val_mae: 0.1229\n",
      "Epoch 50/100\n",
      "1163/1163 [==============================] - 0s 258us/step - loss: 0.0024 - mae: 0.0345 - val_loss: 0.0262 - val_mae: 0.1187\n",
      "Epoch 51/100\n",
      "1163/1163 [==============================] - 0s 278us/step - loss: 0.0023 - mae: 0.0342 - val_loss: 0.0258 - val_mae: 0.1207\n",
      "Epoch 52/100\n",
      "1163/1163 [==============================] - 0s 268us/step - loss: 0.0024 - mae: 0.0347 - val_loss: 0.0265 - val_mae: 0.1209\n",
      "Epoch 53/100\n",
      "1163/1163 [==============================] - 0s 298us/step - loss: 0.0018 - mae: 0.0311 - val_loss: 0.0252 - val_mae: 0.1156\n",
      "Epoch 54/100\n",
      "1163/1163 [==============================] - 0s 267us/step - loss: 0.0022 - mae: 0.0337 - val_loss: 0.0243 - val_mae: 0.1163\n",
      "Epoch 55/100\n",
      "1163/1163 [==============================] - 0s 265us/step - loss: 0.0019 - mae: 0.0317 - val_loss: 0.0276 - val_mae: 0.1224\n",
      "Epoch 56/100\n",
      "1163/1163 [==============================] - 0s 286us/step - loss: 0.0021 - mae: 0.0339 - val_loss: 0.0268 - val_mae: 0.1209\n",
      "Epoch 57/100\n",
      "1163/1163 [==============================] - 0s 280us/step - loss: 0.0018 - mae: 0.0313 - val_loss: 0.0235 - val_mae: 0.1125\n",
      "Epoch 58/100\n",
      "1163/1163 [==============================] - 0s 270us/step - loss: 0.0021 - mae: 0.0339 - val_loss: 0.0239 - val_mae: 0.1165\n",
      "Epoch 59/100\n",
      "1163/1163 [==============================] - 0s 315us/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0214 - val_mae: 0.1130\n",
      "Epoch 60/100\n",
      "1163/1163 [==============================] - 1s 455us/step - loss: 0.0017 - mae: 0.0304 - val_loss: 0.0247 - val_mae: 0.1175\n",
      "Epoch 61/100\n",
      "1163/1163 [==============================] - 0s 221us/step - loss: 0.0021 - mae: 0.0324 - val_loss: 0.0260 - val_mae: 0.1202\n",
      "Epoch 62/100\n",
      "1163/1163 [==============================] - 0s 256us/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.0240 - val_mae: 0.1153\n",
      "Epoch 63/100\n",
      "1163/1163 [==============================] - 0s 305us/step - loss: 0.0017 - mae: 0.0300 - val_loss: 0.0234 - val_mae: 0.1136\n",
      "Epoch 64/100\n",
      "1163/1163 [==============================] - 0s 235us/step - loss: 0.0019 - mae: 0.0311 - val_loss: 0.0256 - val_mae: 0.1179\n",
      "Epoch 65/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0268 - val_mae: 0.1235\n",
      "Epoch 66/100\n",
      "1163/1163 [==============================] - 0s 218us/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.0249 - val_mae: 0.1176\n",
      "Epoch 67/100\n",
      "1163/1163 [==============================] - 0s 242us/step - loss: 0.0017 - mae: 0.0296 - val_loss: 0.0236 - val_mae: 0.1165\n",
      "Epoch 68/100\n",
      "1163/1163 [==============================] - 0s 207us/step - loss: 0.0017 - mae: 0.0287 - val_loss: 0.0228 - val_mae: 0.1156\n",
      "Epoch 69/100\n",
      "1163/1163 [==============================] - 0s 208us/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0252 - val_mae: 0.1201\n",
      "Epoch 70/100\n",
      "1163/1163 [==============================] - 0s 206us/step - loss: 0.0017 - mae: 0.0286 - val_loss: 0.0232 - val_mae: 0.1122\n",
      "Epoch 71/100\n",
      "1163/1163 [==============================] - 0s 239us/step - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0251 - val_mae: 0.1210\n",
      "Epoch 72/100\n",
      "1163/1163 [==============================] - 0s 236us/step - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0219 - val_mae: 0.1110\n",
      "Epoch 73/100\n",
      "1163/1163 [==============================] - 0s 229us/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0242 - val_mae: 0.1155\n",
      "Epoch 74/100\n",
      "1163/1163 [==============================] - 0s 211us/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0251 - val_mae: 0.1163\n",
      "Epoch 75/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0017 - mae: 0.0289 - val_loss: 0.0240 - val_mae: 0.1143\n",
      "Epoch 76/100\n",
      "1163/1163 [==============================] - 0s 194us/step - loss: 0.0015 - mae: 0.0266 - val_loss: 0.0262 - val_mae: 0.1210\n",
      "Epoch 77/100\n",
      "1163/1163 [==============================] - 0s 203us/step - loss: 0.0013 - mae: 0.0266 - val_loss: 0.0227 - val_mae: 0.1126\n",
      "Epoch 78/100\n",
      "1163/1163 [==============================] - 0s 235us/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0246 - val_mae: 0.1153\n",
      "Epoch 79/100\n",
      "1163/1163 [==============================] - 0s 246us/step - loss: 0.0014 - mae: 0.0270 - val_loss: 0.0248 - val_mae: 0.1167\n",
      "Epoch 80/100\n",
      "1163/1163 [==============================] - 0s 190us/step - loss: 0.0014 - mae: 0.0257 - val_loss: 0.0218 - val_mae: 0.1115\n",
      "Epoch 81/100\n",
      "1163/1163 [==============================] - 0s 200us/step - loss: 0.0014 - mae: 0.0266 - val_loss: 0.0245 - val_mae: 0.1163\n",
      "Epoch 82/100\n",
      "1163/1163 [==============================] - 0s 202us/step - loss: 0.0015 - mae: 0.0269 - val_loss: 0.0229 - val_mae: 0.1142\n",
      "Epoch 83/100\n",
      "1163/1163 [==============================] - 0s 363us/step - loss: 0.0013 - mae: 0.0260 - val_loss: 0.0232 - val_mae: 0.1145\n",
      "Epoch 84/100\n",
      "1163/1163 [==============================] - 0s 240us/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0247 - val_mae: 0.1170\n",
      "Epoch 85/100\n",
      "1163/1163 [==============================] - 0s 418us/step - loss: 0.0012 - mae: 0.0246 - val_loss: 0.0230 - val_mae: 0.1130\n",
      "Epoch 86/100\n",
      "1163/1163 [==============================] - 0s 355us/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0227 - val_mae: 0.1106\n",
      "Epoch 87/100\n",
      "1163/1163 [==============================] - 0s 226us/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0244 - val_mae: 0.1134\n",
      "Epoch 88/100\n",
      "1163/1163 [==============================] - 0s 191us/step - loss: 0.0013 - mae: 0.0249 - val_loss: 0.0217 - val_mae: 0.1087\n",
      "Epoch 89/100\n",
      "1163/1163 [==============================] - 0s 196us/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0218 - val_mae: 0.1104\n",
      "Epoch 90/100\n",
      "1163/1163 [==============================] - 0s 202us/step - loss: 0.0012 - mae: 0.0249 - val_loss: 0.0267 - val_mae: 0.1190\n",
      "Epoch 91/100\n",
      "1163/1163 [==============================] - 0s 197us/step - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0234 - val_mae: 0.1153\n",
      "Epoch 92/100\n",
      "1163/1163 [==============================] - 0s 183us/step - loss: 0.0011 - mae: 0.0246 - val_loss: 0.0234 - val_mae: 0.1139\n",
      "Epoch 93/100\n",
      "1163/1163 [==============================] - 0s 208us/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0226 - val_mae: 0.1110\n",
      "Epoch 94/100\n",
      "1163/1163 [==============================] - 0s 222us/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0231 - val_mae: 0.1114\n",
      "Epoch 95/100\n",
      "1163/1163 [==============================] - 0s 180us/step - loss: 0.0012 - mae: 0.0238 - val_loss: 0.0220 - val_mae: 0.1091\n",
      "Epoch 96/100\n",
      "1163/1163 [==============================] - 0s 201us/step - loss: 0.0012 - mae: 0.0254 - val_loss: 0.0238 - val_mae: 0.1153\n",
      "Epoch 97/100\n",
      "1163/1163 [==============================] - 0s 191us/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0288 - val_mae: 0.1231\n",
      "Epoch 98/100\n",
      "1163/1163 [==============================] - 0s 212us/step - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0228 - val_mae: 0.1112\n",
      "Epoch 99/100\n",
      "1163/1163 [==============================] - 0s 212us/step - loss: 9.5172e-04 - mae: 0.0221 - val_loss: 0.0211 - val_mae: 0.1081\n",
      "Epoch 100/100\n",
      "1163/1163 [==============================] - 0s 188us/step - loss: 0.0011 - mae: 0.0235 - val_loss: 0.0229 - val_mae: 0.1108\n",
      "processing fold # 1\n",
      "Train on 1163 samples, validate on 232 samples\n",
      "Epoch 1/100\n",
      "1163/1163 [==============================] - 1s 766us/step - loss: 0.1148 - mae: 0.2492 - val_loss: 0.0768 - val_mae: 0.2030\n",
      "Epoch 2/100\n",
      "1163/1163 [==============================] - 0s 211us/step - loss: 0.0468 - mae: 0.1637 - val_loss: 0.0613 - val_mae: 0.1825\n",
      "Epoch 3/100\n",
      "1163/1163 [==============================] - 1s 462us/step - loss: 0.0305 - mae: 0.1347 - val_loss: 0.0461 - val_mae: 0.1572\n",
      "Epoch 4/100\n",
      "1163/1163 [==============================] - 1s 431us/step - loss: 0.0263 - mae: 0.1225 - val_loss: 0.0576 - val_mae: 0.1806\n",
      "Epoch 5/100\n",
      "1163/1163 [==============================] - 0s 212us/step - loss: 0.0250 - mae: 0.1174 - val_loss: 0.0370 - val_mae: 0.1417\n",
      "Epoch 6/100\n",
      "1163/1163 [==============================] - 0s 215us/step - loss: 0.0207 - mae: 0.1059 - val_loss: 0.0394 - val_mae: 0.1428\n",
      "Epoch 7/100\n",
      "1163/1163 [==============================] - 0s 225us/step - loss: 0.0168 - mae: 0.0960 - val_loss: 0.0409 - val_mae: 0.1481\n",
      "Epoch 8/100\n",
      "1163/1163 [==============================] - 0s 219us/step - loss: 0.0163 - mae: 0.0933 - val_loss: 0.0433 - val_mae: 0.1579\n",
      "Epoch 9/100\n",
      "1163/1163 [==============================] - 0s 208us/step - loss: 0.0128 - mae: 0.0849 - val_loss: 0.0369 - val_mae: 0.1440\n",
      "Epoch 10/100\n",
      "1163/1163 [==============================] - 0s 219us/step - loss: 0.0126 - mae: 0.0834 - val_loss: 0.0507 - val_mae: 0.1520\n",
      "Epoch 11/100\n",
      "1163/1163 [==============================] - 0s 222us/step - loss: 0.0117 - mae: 0.0799 - val_loss: 0.0564 - val_mae: 0.1731\n",
      "Epoch 12/100\n",
      "1163/1163 [==============================] - 0s 217us/step - loss: 0.0113 - mae: 0.0793 - val_loss: 0.0477 - val_mae: 0.1612\n",
      "Epoch 13/100\n",
      "1163/1163 [==============================] - 0s 206us/step - loss: 0.0096 - mae: 0.0716 - val_loss: 0.0440 - val_mae: 0.1430\n",
      "Epoch 14/100\n",
      "1163/1163 [==============================] - 0s 199us/step - loss: 0.0095 - mae: 0.0717 - val_loss: 0.0356 - val_mae: 0.1333\n",
      "Epoch 15/100\n",
      "1163/1163 [==============================] - 0s 199us/step - loss: 0.0086 - mae: 0.0694 - val_loss: 0.0361 - val_mae: 0.1384\n",
      "Epoch 16/100\n",
      "1163/1163 [==============================] - 0s 212us/step - loss: 0.0088 - mae: 0.0693 - val_loss: 0.0473 - val_mae: 0.1467\n",
      "Epoch 17/100\n",
      "1163/1163 [==============================] - 0s 200us/step - loss: 0.0070 - mae: 0.0624 - val_loss: 0.0449 - val_mae: 0.1491\n",
      "Epoch 18/100\n",
      "1163/1163 [==============================] - 0s 254us/step - loss: 0.0076 - mae: 0.0648 - val_loss: 0.0331 - val_mae: 0.1252\n",
      "Epoch 19/100\n",
      "1163/1163 [==============================] - 0s 209us/step - loss: 0.0072 - mae: 0.0614 - val_loss: 0.0330 - val_mae: 0.1238\n",
      "Epoch 20/100\n",
      "1163/1163 [==============================] - 0s 238us/step - loss: 0.0064 - mae: 0.0580 - val_loss: 0.0372 - val_mae: 0.1309\n",
      "Epoch 21/100\n",
      "1163/1163 [==============================] - 0s 217us/step - loss: 0.0060 - mae: 0.0585 - val_loss: 0.0353 - val_mae: 0.1277\n",
      "Epoch 22/100\n",
      "1163/1163 [==============================] - 0s 226us/step - loss: 0.0062 - mae: 0.0576 - val_loss: 0.0388 - val_mae: 0.1341\n",
      "Epoch 23/100\n",
      "1163/1163 [==============================] - 0s 202us/step - loss: 0.0059 - mae: 0.0563 - val_loss: 0.0343 - val_mae: 0.1335\n",
      "Epoch 24/100\n",
      "1163/1163 [==============================] - 0s 236us/step - loss: 0.0056 - mae: 0.0562 - val_loss: 0.0367 - val_mae: 0.1295\n",
      "Epoch 25/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0056 - mae: 0.0530 - val_loss: 0.0306 - val_mae: 0.1194\n",
      "Epoch 26/100\n",
      "1163/1163 [==============================] - 0s 216us/step - loss: 0.0052 - mae: 0.0529 - val_loss: 0.0284 - val_mae: 0.1210\n",
      "Epoch 27/100\n",
      "1163/1163 [==============================] - 0s 255us/step - loss: 0.0051 - mae: 0.0516 - val_loss: 0.0291 - val_mae: 0.1175\n",
      "Epoch 28/100\n",
      "1163/1163 [==============================] - 0s 232us/step - loss: 0.0043 - mae: 0.0466 - val_loss: 0.0299 - val_mae: 0.1205\n",
      "Epoch 29/100\n",
      "1163/1163 [==============================] - 0s 296us/step - loss: 0.0053 - mae: 0.0516 - val_loss: 0.0357 - val_mae: 0.1250\n",
      "Epoch 30/100\n",
      "1163/1163 [==============================] - 0s 283us/step - loss: 0.0048 - mae: 0.0500 - val_loss: 0.0335 - val_mae: 0.1230\n",
      "Epoch 31/100\n",
      "1163/1163 [==============================] - 0s 250us/step - loss: 0.0042 - mae: 0.0469 - val_loss: 0.0312 - val_mae: 0.1212\n",
      "Epoch 32/100\n",
      "1163/1163 [==============================] - 0s 270us/step - loss: 0.0039 - mae: 0.0458 - val_loss: 0.0429 - val_mae: 0.1405\n",
      "Epoch 33/100\n",
      "1163/1163 [==============================] - 0s 273us/step - loss: 0.0041 - mae: 0.0463 - val_loss: 0.0301 - val_mae: 0.1169\n",
      "Epoch 34/100\n",
      "1163/1163 [==============================] - 0s 305us/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0287 - val_mae: 0.1177\n",
      "Epoch 35/100\n",
      "1163/1163 [==============================] - 0s 288us/step - loss: 0.0037 - mae: 0.0445 - val_loss: 0.0293 - val_mae: 0.1208\n",
      "Epoch 36/100\n",
      "1163/1163 [==============================] - 0s 264us/step - loss: 0.0036 - mae: 0.0434 - val_loss: 0.0314 - val_mae: 0.1254\n",
      "Epoch 37/100\n",
      "1163/1163 [==============================] - 0s 281us/step - loss: 0.0031 - mae: 0.0403 - val_loss: 0.0345 - val_mae: 0.1243\n",
      "Epoch 38/100\n",
      "1163/1163 [==============================] - 0s 269us/step - loss: 0.0031 - mae: 0.0409 - val_loss: 0.0334 - val_mae: 0.1284\n",
      "Epoch 39/100\n",
      "1163/1163 [==============================] - 0s 280us/step - loss: 0.0033 - mae: 0.0423 - val_loss: 0.0297 - val_mae: 0.1133\n",
      "Epoch 40/100\n",
      "1163/1163 [==============================] - 0s 285us/step - loss: 0.0028 - mae: 0.0384 - val_loss: 0.0305 - val_mae: 0.1202\n",
      "Epoch 41/100\n",
      "1163/1163 [==============================] - 0s 286us/step - loss: 0.0028 - mae: 0.0386 - val_loss: 0.0300 - val_mae: 0.1161\n",
      "Epoch 42/100\n",
      "1163/1163 [==============================] - 0s 253us/step - loss: 0.0029 - mae: 0.0393 - val_loss: 0.0310 - val_mae: 0.1215\n",
      "Epoch 43/100\n",
      "1163/1163 [==============================] - 0s 242us/step - loss: 0.0031 - mae: 0.0400 - val_loss: 0.0319 - val_mae: 0.1208\n",
      "Epoch 44/100\n",
      "1163/1163 [==============================] - 0s 277us/step - loss: 0.0030 - mae: 0.0402 - val_loss: 0.0301 - val_mae: 0.1167\n",
      "Epoch 45/100\n",
      "1163/1163 [==============================] - 0s 229us/step - loss: 0.0028 - mae: 0.0387 - val_loss: 0.0323 - val_mae: 0.1159\n",
      "Epoch 46/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0028 - mae: 0.0378 - val_loss: 0.0312 - val_mae: 0.1187\n",
      "Epoch 47/100\n",
      "1163/1163 [==============================] - 0s 282us/step - loss: 0.0024 - mae: 0.0354 - val_loss: 0.0348 - val_mae: 0.1238\n",
      "Epoch 48/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0024 - mae: 0.0358 - val_loss: 0.0328 - val_mae: 0.1211\n",
      "Epoch 49/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0025 - mae: 0.0362 - val_loss: 0.0332 - val_mae: 0.1188\n",
      "Epoch 50/100\n",
      "1163/1163 [==============================] - 0s 211us/step - loss: 0.0024 - mae: 0.0360 - val_loss: 0.0323 - val_mae: 0.1161\n",
      "Epoch 51/100\n",
      "1163/1163 [==============================] - 0s 225us/step - loss: 0.0023 - mae: 0.0345 - val_loss: 0.0382 - val_mae: 0.1250\n",
      "Epoch 52/100\n",
      "1163/1163 [==============================] - 0s 206us/step - loss: 0.0024 - mae: 0.0361 - val_loss: 0.0331 - val_mae: 0.1196\n",
      "Epoch 53/100\n",
      "1163/1163 [==============================] - 0s 358us/step - loss: 0.0023 - mae: 0.0346 - val_loss: 0.0297 - val_mae: 0.1141\n",
      "Epoch 54/100\n",
      "1163/1163 [==============================] - 0s 362us/step - loss: 0.0021 - mae: 0.0338 - val_loss: 0.0311 - val_mae: 0.1146\n",
      "Epoch 55/100\n",
      "1163/1163 [==============================] - 0s 233us/step - loss: 0.0022 - mae: 0.0334 - val_loss: 0.0304 - val_mae: 0.1137\n",
      "Epoch 56/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0023 - mae: 0.0340 - val_loss: 0.0297 - val_mae: 0.1144\n",
      "Epoch 57/100\n",
      "1163/1163 [==============================] - 0s 210us/step - loss: 0.0020 - mae: 0.0329 - val_loss: 0.0325 - val_mae: 0.1187\n",
      "Epoch 58/100\n",
      "1163/1163 [==============================] - 0s 225us/step - loss: 0.0021 - mae: 0.0331 - val_loss: 0.0319 - val_mae: 0.1150\n",
      "Epoch 59/100\n",
      "1163/1163 [==============================] - 0s 213us/step - loss: 0.0019 - mae: 0.0315 - val_loss: 0.0281 - val_mae: 0.1140\n",
      "Epoch 60/100\n",
      "1163/1163 [==============================] - 0s 316us/step - loss: 0.0023 - mae: 0.0334 - val_loss: 0.0320 - val_mae: 0.1174\n",
      "Epoch 61/100\n",
      "1163/1163 [==============================] - 0s 217us/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.0276 - val_mae: 0.1131\n",
      "Epoch 62/100\n",
      "1163/1163 [==============================] - 0s 223us/step - loss: 0.0022 - mae: 0.0334 - val_loss: 0.0301 - val_mae: 0.1119\n",
      "Epoch 63/100\n",
      "1163/1163 [==============================] - 0s 260us/step - loss: 0.0018 - mae: 0.0299 - val_loss: 0.0357 - val_mae: 0.1206\n",
      "Epoch 64/100\n",
      "1163/1163 [==============================] - 0s 248us/step - loss: 0.0018 - mae: 0.0304 - val_loss: 0.0284 - val_mae: 0.1104\n",
      "Epoch 65/100\n",
      "1163/1163 [==============================] - 0s 217us/step - loss: 0.0019 - mae: 0.0311 - val_loss: 0.0300 - val_mae: 0.1132\n",
      "Epoch 66/100\n",
      "1163/1163 [==============================] - 1s 436us/step - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0264 - val_mae: 0.1060\n",
      "Epoch 67/100\n",
      "1163/1163 [==============================] - 0s 368us/step - loss: 0.0019 - mae: 0.0303 - val_loss: 0.0257 - val_mae: 0.1085\n",
      "Epoch 68/100\n",
      "1163/1163 [==============================] - 0s 318us/step - loss: 0.0018 - mae: 0.0295 - val_loss: 0.0277 - val_mae: 0.1109\n",
      "Epoch 69/100\n",
      "1163/1163 [==============================] - 1s 558us/step - loss: 0.0017 - mae: 0.0297 - val_loss: 0.0321 - val_mae: 0.1117\n",
      "Epoch 70/100\n",
      "1163/1163 [==============================] - 1s 444us/step - loss: 0.0017 - mae: 0.0301 - val_loss: 0.0288 - val_mae: 0.1105\n",
      "Epoch 71/100\n",
      "1163/1163 [==============================] - 1s 447us/step - loss: 0.0016 - mae: 0.0285 - val_loss: 0.0270 - val_mae: 0.1101\n",
      "Epoch 72/100\n",
      "1163/1163 [==============================] - 1s 461us/step - loss: 0.0015 - mae: 0.0281 - val_loss: 0.0296 - val_mae: 0.1132\n",
      "Epoch 73/100\n",
      "1163/1163 [==============================] - 0s 230us/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0299 - val_mae: 0.1123\n",
      "Epoch 74/100\n",
      "1163/1163 [==============================] - 0s 392us/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0311 - val_mae: 0.1142\n",
      "Epoch 75/100\n",
      "1163/1163 [==============================] - 0s 291us/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0336 - val_mae: 0.1204\n",
      "Epoch 76/100\n",
      "1163/1163 [==============================] - 0s 274us/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0267 - val_mae: 0.1124\n",
      "Epoch 77/100\n",
      "1163/1163 [==============================] - 0s 234us/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0269 - val_mae: 0.1097\n",
      "Epoch 78/100\n",
      "1163/1163 [==============================] - 0s 320us/step - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0278 - val_mae: 0.1070\n",
      "Epoch 79/100\n",
      "1163/1163 [==============================] - 0s 218us/step - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0277 - val_mae: 0.1108\n",
      "Epoch 80/100\n",
      "1163/1163 [==============================] - 0s 232us/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0316 - val_mae: 0.1161\n",
      "Epoch 81/100\n",
      "1163/1163 [==============================] - 0s 246us/step - loss: 0.0013 - mae: 0.0266 - val_loss: 0.0297 - val_mae: 0.1136\n",
      "Epoch 82/100\n",
      "1163/1163 [==============================] - 0s 243us/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0308 - val_mae: 0.1125\n",
      "Epoch 83/100\n",
      "1163/1163 [==============================] - 0s 204us/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0276 - val_mae: 0.1087\n",
      "Epoch 84/100\n",
      "1163/1163 [==============================] - 0s 222us/step - loss: 0.0013 - mae: 0.0258 - val_loss: 0.0273 - val_mae: 0.1097\n",
      "Epoch 85/100\n",
      "1163/1163 [==============================] - 0s 208us/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0274 - val_mae: 0.1108\n",
      "Epoch 86/100\n",
      "1163/1163 [==============================] - 0s 209us/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0309 - val_mae: 0.1146\n",
      "Epoch 87/100\n",
      "1163/1163 [==============================] - 0s 223us/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0289 - val_mae: 0.1095\n",
      "Epoch 88/100\n",
      "1163/1163 [==============================] - 0s 223us/step - loss: 0.0013 - mae: 0.0255 - val_loss: 0.0298 - val_mae: 0.1155\n",
      "Epoch 89/100\n",
      "1163/1163 [==============================] - 0s 242us/step - loss: 0.0013 - mae: 0.0260 - val_loss: 0.0321 - val_mae: 0.1152\n",
      "Epoch 90/100\n",
      "1163/1163 [==============================] - 0s 208us/step - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0330 - val_mae: 0.1138\n",
      "Epoch 91/100\n",
      "1163/1163 [==============================] - 0s 215us/step - loss: 0.0012 - mae: 0.0246 - val_loss: 0.0289 - val_mae: 0.1108\n",
      "Epoch 92/100\n",
      "1163/1163 [==============================] - 0s 197us/step - loss: 0.0012 - mae: 0.0252 - val_loss: 0.0253 - val_mae: 0.1100\n",
      "Epoch 93/100\n",
      "1163/1163 [==============================] - 1s 507us/step - loss: 0.0012 - mae: 0.0249 - val_loss: 0.0283 - val_mae: 0.1124\n",
      "Epoch 94/100\n",
      "1163/1163 [==============================] - 1s 549us/step - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0300 - val_mae: 0.1113\n",
      "Epoch 95/100\n",
      "1163/1163 [==============================] - 0s 298us/step - loss: 0.0012 - mae: 0.0247 - val_loss: 0.0287 - val_mae: 0.1118\n",
      "Epoch 96/100\n",
      "1163/1163 [==============================] - 1s 482us/step - loss: 0.0012 - mae: 0.0242 - val_loss: 0.0272 - val_mae: 0.1093\n",
      "Epoch 97/100\n",
      "1163/1163 [==============================] - 0s 362us/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0318 - val_mae: 0.1135\n",
      "Epoch 98/100\n",
      "1163/1163 [==============================] - 0s 299us/step - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0302 - val_mae: 0.1105\n",
      "Epoch 99/100\n",
      "1163/1163 [==============================] - 0s 248us/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0286 - val_mae: 0.1086\n",
      "Epoch 100/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0010 - mae: 0.0228 - val_loss: 0.0307 - val_mae: 0.1120\n",
      "processing fold # 2\n",
      "Train on 1163 samples, validate on 232 samples\n",
      "Epoch 1/100\n",
      "1163/1163 [==============================] - 1s 626us/step - loss: 0.1068 - mae: 0.2302 - val_loss: 0.0724 - val_mae: 0.1901\n",
      "Epoch 2/100\n",
      "1163/1163 [==============================] - 0s 346us/step - loss: 0.0394 - mae: 0.1488 - val_loss: 0.0388 - val_mae: 0.1503\n",
      "Epoch 3/100\n",
      "1163/1163 [==============================] - 0s 249us/step - loss: 0.0281 - mae: 0.1237 - val_loss: 0.0517 - val_mae: 0.1782\n",
      "Epoch 4/100\n",
      "1163/1163 [==============================] - 0s 236us/step - loss: 0.0239 - mae: 0.1141 - val_loss: 0.0647 - val_mae: 0.1813\n",
      "Epoch 5/100\n",
      "1163/1163 [==============================] - 0s 241us/step - loss: 0.0199 - mae: 0.1049 - val_loss: 0.0526 - val_mae: 0.1879\n",
      "Epoch 6/100\n",
      "1163/1163 [==============================] - 0s 224us/step - loss: 0.0180 - mae: 0.0978 - val_loss: 0.0780 - val_mae: 0.1954\n",
      "Epoch 7/100\n",
      "1163/1163 [==============================] - 0s 234us/step - loss: 0.0135 - mae: 0.0844 - val_loss: 0.0341 - val_mae: 0.1339\n",
      "Epoch 8/100\n",
      "1163/1163 [==============================] - 0s 246us/step - loss: 0.0124 - mae: 0.0834 - val_loss: 0.0341 - val_mae: 0.1362\n",
      "Epoch 9/100\n",
      "1163/1163 [==============================] - 0s 195us/step - loss: 0.0129 - mae: 0.0827 - val_loss: 0.0323 - val_mae: 0.1281\n",
      "Epoch 10/100\n",
      "1163/1163 [==============================] - 0s 213us/step - loss: 0.0109 - mae: 0.0758 - val_loss: 0.0414 - val_mae: 0.1430\n",
      "Epoch 11/100\n",
      "1163/1163 [==============================] - 0s 210us/step - loss: 0.0097 - mae: 0.0722 - val_loss: 0.0308 - val_mae: 0.1247\n",
      "Epoch 12/100\n",
      "1163/1163 [==============================] - 0s 240us/step - loss: 0.0089 - mae: 0.0701 - val_loss: 0.0327 - val_mae: 0.1336\n",
      "Epoch 13/100\n",
      "1163/1163 [==============================] - 0s 216us/step - loss: 0.0084 - mae: 0.0670 - val_loss: 0.0428 - val_mae: 0.1462\n",
      "Epoch 14/100\n",
      "1163/1163 [==============================] - 0s 212us/step - loss: 0.0070 - mae: 0.0604 - val_loss: 0.0309 - val_mae: 0.1345\n",
      "Epoch 15/100\n",
      "1163/1163 [==============================] - 0s 261us/step - loss: 0.0079 - mae: 0.0650 - val_loss: 0.0320 - val_mae: 0.1263\n",
      "Epoch 16/100\n",
      "1163/1163 [==============================] - 0s 211us/step - loss: 0.0072 - mae: 0.0618 - val_loss: 0.0307 - val_mae: 0.1272\n",
      "Epoch 17/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0069 - mae: 0.0607 - val_loss: 0.0348 - val_mae: 0.1290\n",
      "Epoch 18/100\n",
      "1163/1163 [==============================] - 0s 224us/step - loss: 0.0059 - mae: 0.0562 - val_loss: 0.0432 - val_mae: 0.1421\n",
      "Epoch 19/100\n",
      "1163/1163 [==============================] - 0s 204us/step - loss: 0.0061 - mae: 0.0562 - val_loss: 0.0329 - val_mae: 0.1308\n",
      "Epoch 20/100\n",
      "1163/1163 [==============================] - 0s 276us/step - loss: 0.0055 - mae: 0.0549 - val_loss: 0.0318 - val_mae: 0.1299\n",
      "Epoch 21/100\n",
      "1163/1163 [==============================] - 0s 211us/step - loss: 0.0055 - mae: 0.0540 - val_loss: 0.0348 - val_mae: 0.1293\n",
      "Epoch 22/100\n",
      "1163/1163 [==============================] - 0s 243us/step - loss: 0.0051 - mae: 0.0514 - val_loss: 0.0452 - val_mae: 0.1684\n",
      "Epoch 23/100\n",
      "1163/1163 [==============================] - 0s 252us/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0315 - val_mae: 0.1351\n",
      "Epoch 24/100\n",
      "1163/1163 [==============================] - 0s 220us/step - loss: 0.0050 - mae: 0.0509 - val_loss: 0.0320 - val_mae: 0.1249\n",
      "Epoch 25/100\n",
      "1163/1163 [==============================] - 0s 223us/step - loss: 0.0043 - mae: 0.0486 - val_loss: 0.0336 - val_mae: 0.1264\n",
      "Epoch 26/100\n",
      "1163/1163 [==============================] - 0s 232us/step - loss: 0.0047 - mae: 0.0489 - val_loss: 0.0307 - val_mae: 0.1241\n",
      "Epoch 27/100\n",
      "1163/1163 [==============================] - 0s 200us/step - loss: 0.0045 - mae: 0.0490 - val_loss: 0.0329 - val_mae: 0.1284\n",
      "Epoch 28/100\n",
      "1163/1163 [==============================] - 0s 253us/step - loss: 0.0044 - mae: 0.0472 - val_loss: 0.0385 - val_mae: 0.1420\n",
      "Epoch 29/100\n",
      "1163/1163 [==============================] - 0s 221us/step - loss: 0.0040 - mae: 0.0447 - val_loss: 0.0301 - val_mae: 0.1213\n",
      "Epoch 30/100\n",
      "1163/1163 [==============================] - 0s 211us/step - loss: 0.0039 - mae: 0.0465 - val_loss: 0.0342 - val_mae: 0.1319\n",
      "Epoch 31/100\n",
      "1163/1163 [==============================] - 0s 210us/step - loss: 0.0038 - mae: 0.0451 - val_loss: 0.0335 - val_mae: 0.1327\n",
      "Epoch 32/100\n",
      "1163/1163 [==============================] - 0s 227us/step - loss: 0.0042 - mae: 0.0460 - val_loss: 0.0328 - val_mae: 0.1277\n",
      "Epoch 33/100\n",
      "1163/1163 [==============================] - 0s 234us/step - loss: 0.0033 - mae: 0.0431 - val_loss: 0.0302 - val_mae: 0.1252\n",
      "Epoch 34/100\n",
      "1163/1163 [==============================] - 0s 210us/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0307 - val_mae: 0.1323\n",
      "Epoch 35/100\n",
      "1163/1163 [==============================] - 0s 216us/step - loss: 0.0033 - mae: 0.0415 - val_loss: 0.0335 - val_mae: 0.1281\n",
      "Epoch 36/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0032 - mae: 0.0408 - val_loss: 0.0319 - val_mae: 0.1269\n",
      "Epoch 37/100\n",
      "1163/1163 [==============================] - 0s 248us/step - loss: 0.0035 - mae: 0.0428 - val_loss: 0.0324 - val_mae: 0.1248\n",
      "Epoch 38/100\n",
      "1163/1163 [==============================] - 0s 239us/step - loss: 0.0035 - mae: 0.0426 - val_loss: 0.0298 - val_mae: 0.1226\n",
      "Epoch 39/100\n",
      "1163/1163 [==============================] - 0s 199us/step - loss: 0.0025 - mae: 0.0368 - val_loss: 0.0317 - val_mae: 0.1310\n",
      "Epoch 40/100\n",
      "1163/1163 [==============================] - 0s 225us/step - loss: 0.0027 - mae: 0.0376 - val_loss: 0.0315 - val_mae: 0.1310\n",
      "Epoch 41/100\n",
      "1163/1163 [==============================] - 0s 246us/step - loss: 0.0033 - mae: 0.0411 - val_loss: 0.0363 - val_mae: 0.1307\n",
      "Epoch 42/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0028 - mae: 0.0390 - val_loss: 0.0320 - val_mae: 0.1276\n",
      "Epoch 43/100\n",
      "1163/1163 [==============================] - 0s 246us/step - loss: 0.0028 - mae: 0.0382 - val_loss: 0.0363 - val_mae: 0.1294\n",
      "Epoch 44/100\n",
      "1163/1163 [==============================] - 0s 276us/step - loss: 0.0027 - mae: 0.0383 - val_loss: 0.0320 - val_mae: 0.1263\n",
      "Epoch 45/100\n",
      "1163/1163 [==============================] - 0s 223us/step - loss: 0.0027 - mae: 0.0366 - val_loss: 0.0315 - val_mae: 0.1278\n",
      "Epoch 46/100\n",
      "1163/1163 [==============================] - 0s 233us/step - loss: 0.0025 - mae: 0.0351 - val_loss: 0.0309 - val_mae: 0.1294\n",
      "Epoch 47/100\n",
      "1163/1163 [==============================] - 0s 226us/step - loss: 0.0023 - mae: 0.0351 - val_loss: 0.0326 - val_mae: 0.1333\n",
      "Epoch 48/100\n",
      "1163/1163 [==============================] - 0s 239us/step - loss: 0.0025 - mae: 0.0358 - val_loss: 0.0311 - val_mae: 0.1256\n",
      "Epoch 49/100\n",
      "1163/1163 [==============================] - 0s 237us/step - loss: 0.0024 - mae: 0.0356 - val_loss: 0.0281 - val_mae: 0.1220\n",
      "Epoch 50/100\n",
      "1163/1163 [==============================] - 0s 274us/step - loss: 0.0024 - mae: 0.0344 - val_loss: 0.0329 - val_mae: 0.1263\n",
      "Epoch 51/100\n",
      "1163/1163 [==============================] - 0s 271us/step - loss: 0.0021 - mae: 0.0330 - val_loss: 0.0307 - val_mae: 0.1317\n",
      "Epoch 52/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0024 - mae: 0.0359 - val_loss: 0.0297 - val_mae: 0.1220\n",
      "Epoch 53/100\n",
      "1163/1163 [==============================] - 0s 224us/step - loss: 0.0024 - mae: 0.0344 - val_loss: 0.0298 - val_mae: 0.1262\n",
      "Epoch 54/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0025 - mae: 0.0345 - val_loss: 0.0306 - val_mae: 0.1203\n",
      "Epoch 55/100\n",
      "1163/1163 [==============================] - 0s 311us/step - loss: 0.0020 - mae: 0.0314 - val_loss: 0.0290 - val_mae: 0.1234\n",
      "Epoch 56/100\n",
      "1163/1163 [==============================] - 0s 258us/step - loss: 0.0022 - mae: 0.0336 - val_loss: 0.0293 - val_mae: 0.1206\n",
      "Epoch 57/100\n",
      "1163/1163 [==============================] - 0s 279us/step - loss: 0.0022 - mae: 0.0334 - val_loss: 0.0292 - val_mae: 0.1196\n",
      "Epoch 58/100\n",
      "1163/1163 [==============================] - 0s 280us/step - loss: 0.0021 - mae: 0.0321 - val_loss: 0.0305 - val_mae: 0.1313\n",
      "Epoch 59/100\n",
      "1163/1163 [==============================] - 0s 272us/step - loss: 0.0022 - mae: 0.0328 - val_loss: 0.0316 - val_mae: 0.1247\n",
      "Epoch 60/100\n",
      "1163/1163 [==============================] - 0s 259us/step - loss: 0.0019 - mae: 0.0308 - val_loss: 0.0277 - val_mae: 0.1195\n",
      "Epoch 61/100\n",
      "1163/1163 [==============================] - 0s 252us/step - loss: 0.0019 - mae: 0.0315 - val_loss: 0.0294 - val_mae: 0.1250\n",
      "Epoch 62/100\n",
      "1163/1163 [==============================] - 0s 255us/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0313 - val_mae: 0.1261\n",
      "Epoch 63/100\n",
      "1163/1163 [==============================] - 0s 237us/step - loss: 0.0018 - mae: 0.0317 - val_loss: 0.0267 - val_mae: 0.1205\n",
      "Epoch 64/100\n",
      "1163/1163 [==============================] - 0s 257us/step - loss: 0.0017 - mae: 0.0302 - val_loss: 0.0281 - val_mae: 0.1206\n",
      "Epoch 65/100\n",
      "1163/1163 [==============================] - 0s 278us/step - loss: 0.0020 - mae: 0.0311 - val_loss: 0.0265 - val_mae: 0.1167\n",
      "Epoch 66/100\n",
      "1163/1163 [==============================] - 0s 272us/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0272 - val_mae: 0.1144\n",
      "Epoch 67/100\n",
      "1163/1163 [==============================] - 0s 285us/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.0280 - val_mae: 0.1190\n",
      "Epoch 68/100\n",
      "1163/1163 [==============================] - 0s 271us/step - loss: 0.0017 - mae: 0.0286 - val_loss: 0.0284 - val_mae: 0.1162\n",
      "Epoch 69/100\n",
      "1163/1163 [==============================] - 0s 272us/step - loss: 0.0017 - mae: 0.0293 - val_loss: 0.0269 - val_mae: 0.1144\n",
      "Epoch 70/100\n",
      "1163/1163 [==============================] - 0s 237us/step - loss: 0.0018 - mae: 0.0300 - val_loss: 0.0276 - val_mae: 0.1146\n",
      "Epoch 71/100\n",
      "1163/1163 [==============================] - 0s 268us/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0271 - val_mae: 0.1205\n",
      "Epoch 72/100\n",
      "1163/1163 [==============================] - 0s 275us/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0277 - val_mae: 0.1184\n",
      "Epoch 73/100\n",
      "1163/1163 [==============================] - 0s 252us/step - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0280 - val_mae: 0.1245\n",
      "Epoch 74/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0304 - val_mae: 0.1268\n",
      "Epoch 75/100\n",
      "1163/1163 [==============================] - 0s 276us/step - loss: 0.0015 - mae: 0.0277 - val_loss: 0.0262 - val_mae: 0.1156\n",
      "Epoch 76/100\n",
      "1163/1163 [==============================] - 0s 253us/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0271 - val_mae: 0.1200\n",
      "Epoch 77/100\n",
      "1163/1163 [==============================] - 0s 269us/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0261 - val_mae: 0.1167\n",
      "Epoch 78/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0016 - mae: 0.0285 - val_loss: 0.0262 - val_mae: 0.1160\n",
      "Epoch 79/100\n",
      "1163/1163 [==============================] - 0s 264us/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0273 - val_mae: 0.1188\n",
      "Epoch 80/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0261 - val_mae: 0.1155\n",
      "Epoch 81/100\n",
      "1163/1163 [==============================] - 0s 274us/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0299 - val_mae: 0.1217\n",
      "Epoch 82/100\n",
      "1163/1163 [==============================] - 0s 288us/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0260 - val_mae: 0.1147\n",
      "Epoch 83/100\n",
      "1163/1163 [==============================] - 0s 274us/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0262 - val_mae: 0.1160\n",
      "Epoch 84/100\n",
      "1163/1163 [==============================] - 0s 265us/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0266 - val_mae: 0.1148\n",
      "Epoch 85/100\n",
      "1163/1163 [==============================] - 0s 268us/step - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0259 - val_mae: 0.1142\n",
      "Epoch 86/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0272 - val_mae: 0.1198\n",
      "Epoch 87/100\n",
      "1163/1163 [==============================] - 0s 281us/step - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0297 - val_mae: 0.1185\n",
      "Epoch 88/100\n",
      "1163/1163 [==============================] - 0s 256us/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0276 - val_mae: 0.1178\n",
      "Epoch 89/100\n",
      "1163/1163 [==============================] - 0s 293us/step - loss: 0.0013 - mae: 0.0252 - val_loss: 0.0257 - val_mae: 0.1191\n",
      "Epoch 90/100\n",
      "1163/1163 [==============================] - 0s 265us/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0300 - val_mae: 0.1205\n",
      "Epoch 91/100\n",
      "1163/1163 [==============================] - 0s 265us/step - loss: 0.0013 - mae: 0.0262 - val_loss: 0.0264 - val_mae: 0.1192\n",
      "Epoch 92/100\n",
      "1163/1163 [==============================] - 0s 284us/step - loss: 0.0012 - mae: 0.0252 - val_loss: 0.0287 - val_mae: 0.1195\n",
      "Epoch 93/100\n",
      "1163/1163 [==============================] - 0s 273us/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0273 - val_mae: 0.1188\n",
      "Epoch 94/100\n",
      "1163/1163 [==============================] - 0s 249us/step - loss: 0.0012 - mae: 0.0253 - val_loss: 0.0277 - val_mae: 0.1197\n",
      "Epoch 95/100\n",
      "1163/1163 [==============================] - 0s 263us/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0289 - val_mae: 0.1211\n",
      "Epoch 96/100\n",
      "1163/1163 [==============================] - 0s 246us/step - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0285 - val_mae: 0.1184\n",
      "Epoch 97/100\n",
      "1163/1163 [==============================] - 0s 250us/step - loss: 0.0013 - mae: 0.0248 - val_loss: 0.0268 - val_mae: 0.1150\n",
      "Epoch 98/100\n",
      "1163/1163 [==============================] - 0s 267us/step - loss: 0.0012 - mae: 0.0241 - val_loss: 0.0301 - val_mae: 0.1228\n",
      "Epoch 99/100\n",
      "1163/1163 [==============================] - 0s 264us/step - loss: 0.0012 - mae: 0.0247 - val_loss: 0.0275 - val_mae: 0.1183\n",
      "Epoch 100/100\n",
      "1163/1163 [==============================] - 0s 236us/step - loss: 0.0012 - mae: 0.0247 - val_loss: 0.0284 - val_mae: 0.1203\n",
      "processing fold # 3\n",
      "Train on 1163 samples, validate on 232 samples\n",
      "Epoch 1/100\n",
      "1163/1163 [==============================] - 1s 794us/step - loss: 0.0978 - mae: 0.2323 - val_loss: 0.0556 - val_mae: 0.1830\n",
      "Epoch 2/100\n",
      "1163/1163 [==============================] - 0s 240us/step - loss: 0.0459 - mae: 0.1597 - val_loss: 0.0732 - val_mae: 0.2084\n",
      "Epoch 3/100\n",
      "1163/1163 [==============================] - 0s 266us/step - loss: 0.0327 - mae: 0.1350 - val_loss: 0.0478 - val_mae: 0.1633\n",
      "Epoch 4/100\n",
      "1163/1163 [==============================] - 0s 309us/step - loss: 0.0280 - mae: 0.1227 - val_loss: 0.0563 - val_mae: 0.1773\n",
      "Epoch 5/100\n",
      "1163/1163 [==============================] - 0s 285us/step - loss: 0.0219 - mae: 0.1060 - val_loss: 0.0476 - val_mae: 0.1735\n",
      "Epoch 6/100\n",
      "1163/1163 [==============================] - 0s 241us/step - loss: 0.0198 - mae: 0.1043 - val_loss: 0.0458 - val_mae: 0.1616\n",
      "Epoch 7/100\n",
      "1163/1163 [==============================] - 0s 229us/step - loss: 0.0162 - mae: 0.0940 - val_loss: 0.0483 - val_mae: 0.1530\n",
      "Epoch 8/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0170 - mae: 0.0907 - val_loss: 0.0401 - val_mae: 0.1507\n",
      "Epoch 9/100\n",
      "1163/1163 [==============================] - 0s 218us/step - loss: 0.0119 - mae: 0.0819 - val_loss: 0.0314 - val_mae: 0.1313\n",
      "Epoch 10/100\n",
      "1163/1163 [==============================] - ETA: 0s - loss: 0.0115 - mae: 0.079 - 0s 215us/step - loss: 0.0121 - mae: 0.0821 - val_loss: 0.0345 - val_mae: 0.1378\n",
      "Epoch 11/100\n",
      "1163/1163 [==============================] - 0s 199us/step - loss: 0.0114 - mae: 0.0782 - val_loss: 0.0300 - val_mae: 0.1289\n",
      "Epoch 12/100\n",
      "1163/1163 [==============================] - 0s 194us/step - loss: 0.0090 - mae: 0.0710 - val_loss: 0.0316 - val_mae: 0.1268\n",
      "Epoch 13/100\n",
      "1163/1163 [==============================] - 0s 218us/step - loss: 0.0097 - mae: 0.0698 - val_loss: 0.0338 - val_mae: 0.1365\n",
      "Epoch 14/100\n",
      "1163/1163 [==============================] - 0s 201us/step - loss: 0.0084 - mae: 0.0678 - val_loss: 0.0340 - val_mae: 0.1286\n",
      "Epoch 15/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0087 - mae: 0.0673 - val_loss: 0.0311 - val_mae: 0.1306\n",
      "Epoch 16/100\n",
      "1163/1163 [==============================] - 0s 211us/step - loss: 0.0079 - mae: 0.0654 - val_loss: 0.0345 - val_mae: 0.1353\n",
      "Epoch 17/100\n",
      "1163/1163 [==============================] - 0s 200us/step - loss: 0.0070 - mae: 0.0613 - val_loss: 0.0374 - val_mae: 0.1455\n",
      "Epoch 18/100\n",
      "1163/1163 [==============================] - 0s 286us/step - loss: 0.0077 - mae: 0.0629 - val_loss: 0.0276 - val_mae: 0.1162\n",
      "Epoch 19/100\n",
      "1163/1163 [==============================] - 0s 205us/step - loss: 0.0062 - mae: 0.0565 - val_loss: 0.0265 - val_mae: 0.1210\n",
      "Epoch 20/100\n",
      "1163/1163 [==============================] - 0s 198us/step - loss: 0.0070 - mae: 0.0575 - val_loss: 0.0295 - val_mae: 0.1231\n",
      "Epoch 21/100\n",
      "1163/1163 [==============================] - 0s 211us/step - loss: 0.0063 - mae: 0.0562 - val_loss: 0.0279 - val_mae: 0.1198\n",
      "Epoch 22/100\n",
      "1163/1163 [==============================] - 0s 206us/step - loss: 0.0059 - mae: 0.0556 - val_loss: 0.0286 - val_mae: 0.1237\n",
      "Epoch 23/100\n",
      "1163/1163 [==============================] - 0s 221us/step - loss: 0.0056 - mae: 0.0552 - val_loss: 0.0286 - val_mae: 0.1207\n",
      "Epoch 24/100\n",
      "1163/1163 [==============================] - 0s 191us/step - loss: 0.0054 - mae: 0.0525 - val_loss: 0.0297 - val_mae: 0.1194\n",
      "Epoch 25/100\n",
      "1163/1163 [==============================] - 0s 190us/step - loss: 0.0052 - mae: 0.0498 - val_loss: 0.0288 - val_mae: 0.1225\n",
      "Epoch 26/100\n",
      "1163/1163 [==============================] - 0s 196us/step - loss: 0.0055 - mae: 0.0521 - val_loss: 0.0273 - val_mae: 0.1201\n",
      "Epoch 27/100\n",
      "1163/1163 [==============================] - 0s 233us/step - loss: 0.0048 - mae: 0.0500 - val_loss: 0.0289 - val_mae: 0.1228\n",
      "Epoch 28/100\n",
      "1163/1163 [==============================] - 0s 348us/step - loss: 0.0049 - mae: 0.0485 - val_loss: 0.0339 - val_mae: 0.1309\n",
      "Epoch 29/100\n",
      "1163/1163 [==============================] - 0s 199us/step - loss: 0.0045 - mae: 0.0493 - val_loss: 0.0358 - val_mae: 0.1414\n",
      "Epoch 30/100\n",
      "1163/1163 [==============================] - 0s 208us/step - loss: 0.0046 - mae: 0.0481 - val_loss: 0.0286 - val_mae: 0.1208\n",
      "Epoch 31/100\n",
      "1163/1163 [==============================] - 0s 213us/step - loss: 0.0039 - mae: 0.0453 - val_loss: 0.0280 - val_mae: 0.1217\n",
      "Epoch 32/100\n",
      "1163/1163 [==============================] - 0s 183us/step - loss: 0.0041 - mae: 0.0466 - val_loss: 0.0264 - val_mae: 0.1168\n",
      "Epoch 33/100\n",
      "1163/1163 [==============================] - 0s 194us/step - loss: 0.0035 - mae: 0.0433 - val_loss: 0.0357 - val_mae: 0.1370\n",
      "Epoch 34/100\n",
      "1163/1163 [==============================] - 0s 206us/step - loss: 0.0043 - mae: 0.0455 - val_loss: 0.0394 - val_mae: 0.1426\n",
      "Epoch 35/100\n",
      "1163/1163 [==============================] - 0s 205us/step - loss: 0.0038 - mae: 0.0446 - val_loss: 0.0293 - val_mae: 0.1257\n",
      "Epoch 36/100\n",
      "1163/1163 [==============================] - 0s 192us/step - loss: 0.0034 - mae: 0.0423 - val_loss: 0.0280 - val_mae: 0.1224\n",
      "Epoch 37/100\n",
      "1163/1163 [==============================] - 0s 184us/step - loss: 0.0038 - mae: 0.0436 - val_loss: 0.0266 - val_mae: 0.1184\n",
      "Epoch 38/100\n",
      "1163/1163 [==============================] - 0s 189us/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0269 - val_mae: 0.1209\n",
      "Epoch 39/100\n",
      "1163/1163 [==============================] - 0s 189us/step - loss: 0.0031 - mae: 0.0395 - val_loss: 0.0257 - val_mae: 0.1155\n",
      "Epoch 40/100\n",
      "1163/1163 [==============================] - 0s 214us/step - loss: 0.0034 - mae: 0.0413 - val_loss: 0.0280 - val_mae: 0.1173\n",
      "Epoch 41/100\n",
      "1163/1163 [==============================] - 0s 194us/step - loss: 0.0032 - mae: 0.0409 - val_loss: 0.0272 - val_mae: 0.1180\n",
      "Epoch 42/100\n",
      "1163/1163 [==============================] - 0s 191us/step - loss: 0.0034 - mae: 0.0405 - val_loss: 0.0284 - val_mae: 0.1244\n",
      "Epoch 43/100\n",
      "1163/1163 [==============================] - 0s 191us/step - loss: 0.0033 - mae: 0.0412 - val_loss: 0.0296 - val_mae: 0.1213\n",
      "Epoch 44/100\n",
      "1163/1163 [==============================] - 0s 192us/step - loss: 0.0030 - mae: 0.0384 - val_loss: 0.0297 - val_mae: 0.1255\n",
      "Epoch 45/100\n",
      "1163/1163 [==============================] - 0s 217us/step - loss: 0.0028 - mae: 0.0379 - val_loss: 0.0256 - val_mae: 0.1162\n",
      "Epoch 46/100\n",
      "1163/1163 [==============================] - 0s 265us/step - loss: 0.0030 - mae: 0.0388 - val_loss: 0.0279 - val_mae: 0.1240\n",
      "Epoch 47/100\n",
      "1163/1163 [==============================] - 0s 248us/step - loss: 0.0026 - mae: 0.0364 - val_loss: 0.0327 - val_mae: 0.1333\n",
      "Epoch 48/100\n",
      "1163/1163 [==============================] - 0s 262us/step - loss: 0.0030 - mae: 0.0377 - val_loss: 0.0266 - val_mae: 0.1161\n",
      "Epoch 49/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0026 - mae: 0.0364 - val_loss: 0.0275 - val_mae: 0.1172\n",
      "Epoch 50/100\n",
      "1163/1163 [==============================] - 0s 242us/step - loss: 0.0026 - mae: 0.0363 - val_loss: 0.0259 - val_mae: 0.1138\n",
      "Epoch 51/100\n",
      "1163/1163 [==============================] - 0s 273us/step - loss: 0.0023 - mae: 0.0332 - val_loss: 0.0284 - val_mae: 0.1182\n",
      "Epoch 52/100\n",
      "1163/1163 [==============================] - 0s 264us/step - loss: 0.0029 - mae: 0.0385 - val_loss: 0.0293 - val_mae: 0.1201\n",
      "Epoch 53/100\n",
      "1163/1163 [==============================] - 0s 250us/step - loss: 0.0025 - mae: 0.0349 - val_loss: 0.0261 - val_mae: 0.1179\n",
      "Epoch 54/100\n",
      "1163/1163 [==============================] - 0s 270us/step - loss: 0.0025 - mae: 0.0354 - val_loss: 0.0272 - val_mae: 0.1188\n",
      "Epoch 55/100\n",
      "1163/1163 [==============================] - 0s 253us/step - loss: 0.0023 - mae: 0.0348 - val_loss: 0.0258 - val_mae: 0.1128\n",
      "Epoch 56/100\n",
      "1163/1163 [==============================] - 0s 264us/step - loss: 0.0028 - mae: 0.0365 - val_loss: 0.0255 - val_mae: 0.1135\n",
      "Epoch 57/100\n",
      "1163/1163 [==============================] - 0s 224us/step - loss: 0.0020 - mae: 0.0319 - val_loss: 0.0246 - val_mae: 0.1109\n",
      "Epoch 58/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0021 - mae: 0.0328 - val_loss: 0.0288 - val_mae: 0.1235\n",
      "Epoch 59/100\n",
      "1163/1163 [==============================] - 0s 235us/step - loss: 0.0021 - mae: 0.0333 - val_loss: 0.0261 - val_mae: 0.1168\n",
      "Epoch 60/100\n",
      "1163/1163 [==============================] - 0s 279us/step - loss: 0.0021 - mae: 0.0329 - val_loss: 0.0260 - val_mae: 0.1146\n",
      "Epoch 61/100\n",
      "1163/1163 [==============================] - 0s 274us/step - loss: 0.0022 - mae: 0.0329 - val_loss: 0.0276 - val_mae: 0.1194\n",
      "Epoch 62/100\n",
      "1163/1163 [==============================] - 0s 286us/step - loss: 0.0020 - mae: 0.0322 - val_loss: 0.0265 - val_mae: 0.1155\n",
      "Epoch 63/100\n",
      "1163/1163 [==============================] - 0s 275us/step - loss: 0.0024 - mae: 0.0335 - val_loss: 0.0261 - val_mae: 0.1146\n",
      "Epoch 64/100\n",
      "1163/1163 [==============================] - 0s 267us/step - loss: 0.0019 - mae: 0.0309 - val_loss: 0.0252 - val_mae: 0.1140\n",
      "Epoch 65/100\n",
      "1163/1163 [==============================] - 0s 261us/step - loss: 0.0020 - mae: 0.0315 - val_loss: 0.0255 - val_mae: 0.1129\n",
      "Epoch 66/100\n",
      "1163/1163 [==============================] - 0s 241us/step - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 67/100\n",
      "1163/1163 [==============================] - 0s 256us/step - loss: 0.0018 - mae: 0.0302 - val_loss: 0.0244 - val_mae: 0.1114\n",
      "Epoch 68/100\n",
      "1163/1163 [==============================] - 0s 246us/step - loss: 0.0019 - mae: 0.0320 - val_loss: 0.0229 - val_mae: 0.1076\n",
      "Epoch 69/100\n",
      "1163/1163 [==============================] - 0s 275us/step - loss: 0.0021 - mae: 0.0322 - val_loss: 0.0252 - val_mae: 0.1110\n",
      "Epoch 70/100\n",
      "1163/1163 [==============================] - 0s 273us/step - loss: 0.0017 - mae: 0.0295 - val_loss: 0.0258 - val_mae: 0.1158\n",
      "Epoch 71/100\n",
      "1163/1163 [==============================] - 0s 238us/step - loss: 0.0018 - mae: 0.0295 - val_loss: 0.0250 - val_mae: 0.1116\n",
      "Epoch 72/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0019 - mae: 0.0306 - val_loss: 0.0246 - val_mae: 0.1106\n",
      "Epoch 73/100\n",
      "1163/1163 [==============================] - 0s 250us/step - loss: 0.0017 - mae: 0.0293 - val_loss: 0.0223 - val_mae: 0.1080\n",
      "Epoch 74/100\n",
      "1163/1163 [==============================] - 0s 256us/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0243 - val_mae: 0.1128\n",
      "Epoch 75/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0017 - mae: 0.0291 - val_loss: 0.0265 - val_mae: 0.1140\n",
      "Epoch 76/100\n",
      "1163/1163 [==============================] - 0s 251us/step - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0260 - val_mae: 0.1102\n",
      "Epoch 77/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0018 - mae: 0.0291 - val_loss: 0.0240 - val_mae: 0.1107\n",
      "Epoch 78/100\n",
      "1163/1163 [==============================] - 0s 270us/step - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0243 - val_mae: 0.1102\n",
      "Epoch 79/100\n",
      "1163/1163 [==============================] - 0s 243us/step - loss: 0.0017 - mae: 0.0280 - val_loss: 0.0251 - val_mae: 0.1118\n",
      "Epoch 80/100\n",
      "1163/1163 [==============================] - 0s 286us/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0257 - val_mae: 0.1136\n",
      "Epoch 81/100\n",
      "1163/1163 [==============================] - 0s 275us/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0228 - val_mae: 0.1070\n",
      "Epoch 82/100\n",
      "1163/1163 [==============================] - 0s 243us/step - loss: 0.0016 - mae: 0.0287 - val_loss: 0.0232 - val_mae: 0.1055\n",
      "Epoch 83/100\n",
      "1163/1163 [==============================] - 0s 263us/step - loss: 0.0014 - mae: 0.0263 - val_loss: 0.0245 - val_mae: 0.1146\n",
      "Epoch 84/100\n",
      "1163/1163 [==============================] - 0s 240us/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0243 - val_mae: 0.1125\n",
      "Epoch 85/100\n",
      "1163/1163 [==============================] - 0s 264us/step - loss: 0.0015 - mae: 0.0277 - val_loss: 0.0216 - val_mae: 0.1027\n",
      "Epoch 86/100\n",
      "1163/1163 [==============================] - 0s 275us/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0211 - val_mae: 0.1040\n",
      "Epoch 87/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0017 - mae: 0.0286 - val_loss: 0.0217 - val_mae: 0.1034\n",
      "Epoch 88/100\n",
      "1163/1163 [==============================] - 0s 248us/step - loss: 0.0014 - mae: 0.0259 - val_loss: 0.0208 - val_mae: 0.1000\n",
      "Epoch 89/100\n",
      "1163/1163 [==============================] - 0s 263us/step - loss: 0.0016 - mae: 0.0280 - val_loss: 0.0228 - val_mae: 0.1051\n",
      "Epoch 90/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0224 - val_mae: 0.1045\n",
      "Epoch 91/100\n",
      "1163/1163 [==============================] - 0s 243us/step - loss: 0.0014 - mae: 0.0259 - val_loss: 0.0267 - val_mae: 0.1126\n",
      "Epoch 92/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0209 - val_mae: 0.1012\n",
      "Epoch 93/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0014 - mae: 0.0259 - val_loss: 0.0230 - val_mae: 0.1092\n",
      "Epoch 94/100\n",
      "1163/1163 [==============================] - 0s 264us/step - loss: 0.0014 - mae: 0.0254 - val_loss: 0.0210 - val_mae: 0.1045\n",
      "Epoch 95/100\n",
      "1163/1163 [==============================] - 0s 221us/step - loss: 0.0012 - mae: 0.0247 - val_loss: 0.0215 - val_mae: 0.1044\n",
      "Epoch 96/100\n",
      "1163/1163 [==============================] - 0s 293us/step - loss: 0.0013 - mae: 0.0258 - val_loss: 0.0232 - val_mae: 0.1063\n",
      "Epoch 97/100\n",
      "1163/1163 [==============================] - 0s 258us/step - loss: 0.0012 - mae: 0.0247 - val_loss: 0.0221 - val_mae: 0.1024\n",
      "Epoch 98/100\n",
      "1163/1163 [==============================] - 0s 274us/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0229 - val_mae: 0.1044\n",
      "Epoch 99/100\n",
      "1163/1163 [==============================] - 0s 257us/step - loss: 0.0013 - mae: 0.0255 - val_loss: 0.0237 - val_mae: 0.1103\n",
      "Epoch 100/100\n",
      "1163/1163 [==============================] - 0s 261us/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0247 - val_mae: 0.1056\n",
      "processing fold # 4\n",
      "Train on 1163 samples, validate on 232 samples\n",
      "Epoch 1/100\n",
      "1163/1163 [==============================] - 1s 864us/step - loss: 0.0846 - mae: 0.2159 - val_loss: 0.0481 - val_mae: 0.1667\n",
      "Epoch 2/100\n",
      "1163/1163 [==============================] - 0s 292us/step - loss: 0.0399 - mae: 0.1470 - val_loss: 0.0459 - val_mae: 0.1710\n",
      "Epoch 3/100\n",
      "1163/1163 [==============================] - 0s 285us/step - loss: 0.0282 - mae: 0.1255 - val_loss: 0.0385 - val_mae: 0.1413\n",
      "Epoch 4/100\n",
      "1163/1163 [==============================] - 0s 285us/step - loss: 0.0239 - mae: 0.1145 - val_loss: 0.0362 - val_mae: 0.1356\n",
      "Epoch 5/100\n",
      "1163/1163 [==============================] - 0s 297us/step - loss: 0.0191 - mae: 0.1034 - val_loss: 0.0344 - val_mae: 0.1367\n",
      "Epoch 6/100\n",
      "1163/1163 [==============================] - 0s 294us/step - loss: 0.0175 - mae: 0.0977 - val_loss: 0.0273 - val_mae: 0.1262\n",
      "Epoch 7/100\n",
      "1163/1163 [==============================] - 0s 291us/step - loss: 0.0144 - mae: 0.0902 - val_loss: 0.0323 - val_mae: 0.1433\n",
      "Epoch 8/100\n",
      "1163/1163 [==============================] - 0s 304us/step - loss: 0.0137 - mae: 0.0880 - val_loss: 0.0265 - val_mae: 0.1208\n",
      "Epoch 9/100\n",
      "1163/1163 [==============================] - 0s 318us/step - loss: 0.0116 - mae: 0.0813 - val_loss: 0.0459 - val_mae: 0.1562\n",
      "Epoch 10/100\n",
      "1163/1163 [==============================] - 0s 259us/step - loss: 0.0114 - mae: 0.0794 - val_loss: 0.0308 - val_mae: 0.1392\n",
      "Epoch 11/100\n",
      "1163/1163 [==============================] - 0s 284us/step - loss: 0.0111 - mae: 0.0780 - val_loss: 0.0233 - val_mae: 0.1140\n",
      "Epoch 12/100\n",
      "1163/1163 [==============================] - 0s 304us/step - loss: 0.0096 - mae: 0.0735 - val_loss: 0.0189 - val_mae: 0.1089\n",
      "Epoch 13/100\n",
      "1163/1163 [==============================] - 0s 282us/step - loss: 0.0087 - mae: 0.0706 - val_loss: 0.0267 - val_mae: 0.1212\n",
      "Epoch 14/100\n",
      "1163/1163 [==============================] - 0s 252us/step - loss: 0.0087 - mae: 0.0704 - val_loss: 0.0231 - val_mae: 0.1144\n",
      "Epoch 15/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0078 - mae: 0.0661 - val_loss: 0.0226 - val_mae: 0.1202\n",
      "Epoch 16/100\n",
      "1163/1163 [==============================] - 0s 237us/step - loss: 0.0078 - mae: 0.0644 - val_loss: 0.0250 - val_mae: 0.1211\n",
      "Epoch 17/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0072 - mae: 0.0633 - val_loss: 0.0233 - val_mae: 0.1207\n",
      "Epoch 18/100\n",
      "1163/1163 [==============================] - 0s 256us/step - loss: 0.0064 - mae: 0.0616 - val_loss: 0.0232 - val_mae: 0.1204\n",
      "Epoch 19/100\n",
      "1163/1163 [==============================] - 0s 256us/step - loss: 0.0064 - mae: 0.0600 - val_loss: 0.0244 - val_mae: 0.1195\n",
      "Epoch 20/100\n",
      "1163/1163 [==============================] - 0s 246us/step - loss: 0.0057 - mae: 0.0574 - val_loss: 0.0284 - val_mae: 0.1259\n",
      "Epoch 21/100\n",
      "1163/1163 [==============================] - 0s 303us/step - loss: 0.0060 - mae: 0.0562 - val_loss: 0.0238 - val_mae: 0.1200\n",
      "Epoch 22/100\n",
      "1163/1163 [==============================] - 0s 264us/step - loss: 0.0058 - mae: 0.0555 - val_loss: 0.0259 - val_mae: 0.1245\n",
      "Epoch 23/100\n",
      "1163/1163 [==============================] - 0s 222us/step - loss: 0.0049 - mae: 0.0532 - val_loss: 0.0243 - val_mae: 0.1176\n",
      "Epoch 24/100\n",
      "1163/1163 [==============================] - 0s 214us/step - loss: 0.0049 - mae: 0.0522 - val_loss: 0.0244 - val_mae: 0.1123\n",
      "Epoch 25/100\n",
      "1163/1163 [==============================] - 0s 228us/step - loss: 0.0048 - mae: 0.0519 - val_loss: 0.0228 - val_mae: 0.1147\n",
      "Epoch 26/100\n",
      "1163/1163 [==============================] - 0s 234us/step - loss: 0.0051 - mae: 0.0531 - val_loss: 0.0242 - val_mae: 0.1130\n",
      "Epoch 27/100\n",
      "1163/1163 [==============================] - 0s 212us/step - loss: 0.0043 - mae: 0.0489 - val_loss: 0.0227 - val_mae: 0.1170\n",
      "Epoch 28/100\n",
      "1163/1163 [==============================] - 0s 218us/step - loss: 0.0041 - mae: 0.0479 - val_loss: 0.0222 - val_mae: 0.1143\n",
      "Epoch 29/100\n",
      "1163/1163 [==============================] - 0s 216us/step - loss: 0.0045 - mae: 0.0480 - val_loss: 0.0246 - val_mae: 0.1214\n",
      "Epoch 30/100\n",
      "1163/1163 [==============================] - 0s 230us/step - loss: 0.0039 - mae: 0.0468 - val_loss: 0.0233 - val_mae: 0.1136\n",
      "Epoch 31/100\n",
      "1163/1163 [==============================] - 0s 227us/step - loss: 0.0040 - mae: 0.0464 - val_loss: 0.0230 - val_mae: 0.1159\n",
      "Epoch 32/100\n",
      "1163/1163 [==============================] - 0s 227us/step - loss: 0.0037 - mae: 0.0459 - val_loss: 0.0233 - val_mae: 0.1130\n",
      "Epoch 33/100\n",
      "1163/1163 [==============================] - 0s 213us/step - loss: 0.0036 - mae: 0.0439 - val_loss: 0.0298 - val_mae: 0.1313\n",
      "Epoch 34/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0035 - mae: 0.0444 - val_loss: 0.0329 - val_mae: 0.1319\n",
      "Epoch 35/100\n",
      "1163/1163 [==============================] - 0s 228us/step - loss: 0.0035 - mae: 0.0426 - val_loss: 0.0273 - val_mae: 0.1299\n",
      "Epoch 36/100\n",
      "1163/1163 [==============================] - 0s 216us/step - loss: 0.0036 - mae: 0.0431 - val_loss: 0.0226 - val_mae: 0.1135\n",
      "Epoch 37/100\n",
      "1163/1163 [==============================] - 0s 208us/step - loss: 0.0032 - mae: 0.0415 - val_loss: 0.0202 - val_mae: 0.1075\n",
      "Epoch 38/100\n",
      "1163/1163 [==============================] - 0s 237us/step - loss: 0.0032 - mae: 0.0413 - val_loss: 0.0231 - val_mae: 0.1118\n",
      "Epoch 39/100\n",
      "1163/1163 [==============================] - 0s 369us/step - loss: 0.0033 - mae: 0.0424 - val_loss: 0.0255 - val_mae: 0.1157\n",
      "Epoch 40/100\n",
      "1163/1163 [==============================] - 0s 265us/step - loss: 0.0030 - mae: 0.0395 - val_loss: 0.0219 - val_mae: 0.1107\n",
      "Epoch 41/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0026 - mae: 0.0372 - val_loss: 0.0214 - val_mae: 0.1107\n",
      "Epoch 42/100\n",
      "1163/1163 [==============================] - 0s 204us/step - loss: 0.0031 - mae: 0.0403 - val_loss: 0.0239 - val_mae: 0.1204\n",
      "Epoch 43/100\n",
      "1163/1163 [==============================] - 0s 218us/step - loss: 0.0028 - mae: 0.0390 - val_loss: 0.0198 - val_mae: 0.1067\n",
      "Epoch 44/100\n",
      "1163/1163 [==============================] - 0s 210us/step - loss: 0.0028 - mae: 0.0380 - val_loss: 0.0229 - val_mae: 0.1107\n",
      "Epoch 45/100\n",
      "1163/1163 [==============================] - 0s 243us/step - loss: 0.0023 - mae: 0.0357 - val_loss: 0.0214 - val_mae: 0.1124\n",
      "Epoch 46/100\n",
      "1163/1163 [==============================] - 0s 197us/step - loss: 0.0025 - mae: 0.0364 - val_loss: 0.0214 - val_mae: 0.1133\n",
      "Epoch 47/100\n",
      "1163/1163 [==============================] - 0s 216us/step - loss: 0.0025 - mae: 0.0367 - val_loss: 0.0242 - val_mae: 0.1201\n",
      "Epoch 48/100\n",
      "1163/1163 [==============================] - 0s 213us/step - loss: 0.0026 - mae: 0.0357 - val_loss: 0.0229 - val_mae: 0.1115\n",
      "Epoch 49/100\n",
      "1163/1163 [==============================] - 0s 216us/step - loss: 0.0023 - mae: 0.0354 - val_loss: 0.0203 - val_mae: 0.1047\n",
      "Epoch 50/100\n",
      "1163/1163 [==============================] - 0s 234us/step - loss: 0.0025 - mae: 0.0362 - val_loss: 0.0214 - val_mae: 0.1101\n",
      "Epoch 51/100\n",
      "1163/1163 [==============================] - 0s 264us/step - loss: 0.0024 - mae: 0.0345 - val_loss: 0.0195 - val_mae: 0.1081\n",
      "Epoch 52/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0022 - mae: 0.0346 - val_loss: 0.0206 - val_mae: 0.1086\n",
      "Epoch 53/100\n",
      "1163/1163 [==============================] - 0s 248us/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0202 - val_mae: 0.1078\n",
      "Epoch 54/100\n",
      "1163/1163 [==============================] - 0s 248us/step - loss: 0.0021 - mae: 0.0340 - val_loss: 0.0178 - val_mae: 0.0992\n",
      "Epoch 55/100\n",
      "1163/1163 [==============================] - 0s 220us/step - loss: 0.0022 - mae: 0.0345 - val_loss: 0.0232 - val_mae: 0.1138\n",
      "Epoch 56/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0176 - val_mae: 0.1008\n",
      "Epoch 57/100\n",
      "1163/1163 [==============================] - 0s 262us/step - loss: 0.0021 - mae: 0.0335 - val_loss: 0.0200 - val_mae: 0.1050\n",
      "Epoch 58/100\n",
      "1163/1163 [==============================] - 0s 226us/step - loss: 0.0021 - mae: 0.0332 - val_loss: 0.0194 - val_mae: 0.1055\n",
      "Epoch 59/100\n",
      "1163/1163 [==============================] - 0s 229us/step - loss: 0.0019 - mae: 0.0305 - val_loss: 0.0210 - val_mae: 0.1081\n",
      "Epoch 60/100\n",
      "1163/1163 [==============================] - 0s 278us/step - loss: 0.0021 - mae: 0.0332 - val_loss: 0.0188 - val_mae: 0.1021\n",
      "Epoch 61/100\n",
      "1163/1163 [==============================] - 0s 268us/step - loss: 0.0020 - mae: 0.0317 - val_loss: 0.0184 - val_mae: 0.1002\n",
      "Epoch 62/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0018 - mae: 0.0304 - val_loss: 0.0206 - val_mae: 0.1057\n",
      "Epoch 63/100\n",
      "1163/1163 [==============================] - 0s 220us/step - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0199 - val_mae: 0.1042\n",
      "Epoch 64/100\n",
      "1163/1163 [==============================] - 0s 200us/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0220 - val_mae: 0.1118\n",
      "Epoch 65/100\n",
      "1163/1163 [==============================] - 0s 254us/step - loss: 0.0017 - mae: 0.0306 - val_loss: 0.0181 - val_mae: 0.0990\n",
      "Epoch 66/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0214 - val_mae: 0.1110\n",
      "Epoch 67/100\n",
      "1163/1163 [==============================] - 0s 189us/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0188 - val_mae: 0.1008\n",
      "Epoch 68/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0019 - mae: 0.0313 - val_loss: 0.0202 - val_mae: 0.1053\n",
      "Epoch 69/100\n",
      "1163/1163 [==============================] - 0s 194us/step - loss: 0.0018 - mae: 0.0301 - val_loss: 0.0196 - val_mae: 0.1019\n",
      "Epoch 70/100\n",
      "1163/1163 [==============================] - 0s 195us/step - loss: 0.0017 - mae: 0.0304 - val_loss: 0.0240 - val_mae: 0.1190\n",
      "Epoch 71/100\n",
      "1163/1163 [==============================] - 0s 193us/step - loss: 0.0017 - mae: 0.0291 - val_loss: 0.0228 - val_mae: 0.1100\n",
      "Epoch 72/100\n",
      "1163/1163 [==============================] - 0s 195us/step - loss: 0.0016 - mae: 0.0287 - val_loss: 0.0219 - val_mae: 0.1098\n",
      "Epoch 73/100\n",
      "1163/1163 [==============================] - 0s 214us/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0178 - val_mae: 0.0977\n",
      "Epoch 74/100\n",
      "1163/1163 [==============================] - 0s 187us/step - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0187 - val_mae: 0.1011\n",
      "Epoch 75/100\n",
      "1163/1163 [==============================] - 0s 197us/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0207 - val_mae: 0.1068\n",
      "Epoch 76/100\n",
      "1163/1163 [==============================] - 0s 199us/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0217 - val_mae: 0.1070\n",
      "Epoch 77/100\n",
      "1163/1163 [==============================] - 0s 201us/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0203 - val_mae: 0.1037\n",
      "Epoch 78/100\n",
      "1163/1163 [==============================] - 0s 194us/step - loss: 0.0015 - mae: 0.0277 - val_loss: 0.0201 - val_mae: 0.1057\n",
      "Epoch 79/100\n",
      "1163/1163 [==============================] - 0s 188us/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0206 - val_mae: 0.1043\n",
      "Epoch 80/100\n",
      "1163/1163 [==============================] - 0s 222us/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0183 - val_mae: 0.1017\n",
      "Epoch 81/100\n",
      "1163/1163 [==============================] - 0s 202us/step - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0176 - val_mae: 0.0950\n",
      "Epoch 82/100\n",
      "1163/1163 [==============================] - 0s 295us/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0193 - val_mae: 0.1042\n",
      "Epoch 83/100\n",
      "1163/1163 [==============================] - 0s 188us/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0198 - val_mae: 0.1028\n",
      "Epoch 84/100\n",
      "1163/1163 [==============================] - 0s 196us/step - loss: 0.0014 - mae: 0.0267 - val_loss: 0.0182 - val_mae: 0.1003\n",
      "Epoch 85/100\n",
      "1163/1163 [==============================] - 0s 208us/step - loss: 0.0014 - mae: 0.0272 - val_loss: 0.0198 - val_mae: 0.1039\n",
      "Epoch 86/100\n",
      "1163/1163 [==============================] - 0s 216us/step - loss: 0.0014 - mae: 0.0266 - val_loss: 0.0194 - val_mae: 0.1010\n",
      "Epoch 87/100\n",
      "1163/1163 [==============================] - 0s 191us/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0195 - val_mae: 0.1028\n",
      "Epoch 88/100\n",
      "1163/1163 [==============================] - 0s 191us/step - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0187 - val_mae: 0.1016\n",
      "Epoch 89/100\n",
      "1163/1163 [==============================] - 0s 194us/step - loss: 0.0013 - mae: 0.0251 - val_loss: 0.0201 - val_mae: 0.1036\n",
      "Epoch 90/100\n",
      "1163/1163 [==============================] - 0s 201us/step - loss: 0.0012 - mae: 0.0253 - val_loss: 0.0180 - val_mae: 0.1012\n",
      "Epoch 91/100\n",
      "1163/1163 [==============================] - 0s 195us/step - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0203 - val_mae: 0.1013\n",
      "Epoch 92/100\n",
      "1163/1163 [==============================] - 0s 198us/step - loss: 0.0013 - mae: 0.0257 - val_loss: 0.0182 - val_mae: 0.0991\n",
      "Epoch 93/100\n",
      "1163/1163 [==============================] - 0s 189us/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0185 - val_mae: 0.0989\n",
      "Epoch 94/100\n",
      "1163/1163 [==============================] - 0s 195us/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0183 - val_mae: 0.0983\n",
      "Epoch 95/100\n",
      "1163/1163 [==============================] - 0s 211us/step - loss: 0.0012 - mae: 0.0246 - val_loss: 0.0181 - val_mae: 0.1003\n",
      "Epoch 96/100\n",
      "1163/1163 [==============================] - 0s 205us/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0189 - val_mae: 0.1000\n",
      "Epoch 97/100\n",
      "1163/1163 [==============================] - 0s 249us/step - loss: 0.0012 - mae: 0.0246 - val_loss: 0.0185 - val_mae: 0.1007\n",
      "Epoch 98/100\n",
      "1163/1163 [==============================] - 0s 188us/step - loss: 0.0013 - mae: 0.0251 - val_loss: 0.0177 - val_mae: 0.0957\n",
      "Epoch 99/100\n",
      "1163/1163 [==============================] - 0s 217us/step - loss: 0.0012 - mae: 0.0247 - val_loss: 0.0170 - val_mae: 0.0940\n",
      "Epoch 100/100\n",
      "1163/1163 [==============================] - 0s 210us/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0169 - val_mae: 0.0954\n",
      "processing fold # 5\n",
      "Train on 1163 samples, validate on 232 samples\n",
      "Epoch 1/100\n",
      "1163/1163 [==============================] - 1s 777us/step - loss: 0.0824 - mae: 0.2111 - val_loss: 0.0365 - val_mae: 0.1427\n",
      "Epoch 2/100\n",
      "1163/1163 [==============================] - 0s 277us/step - loss: 0.0382 - mae: 0.1427 - val_loss: 0.0705 - val_mae: 0.1985\n",
      "Epoch 3/100\n",
      "1163/1163 [==============================] - 0s 251us/step - loss: 0.0286 - mae: 0.1259 - val_loss: 0.0305 - val_mae: 0.1346\n",
      "Epoch 4/100\n",
      "1163/1163 [==============================] - 0s 224us/step - loss: 0.0216 - mae: 0.1075 - val_loss: 0.0264 - val_mae: 0.1227\n",
      "Epoch 5/100\n",
      "1163/1163 [==============================] - 0s 230us/step - loss: 0.0205 - mae: 0.1042 - val_loss: 0.0225 - val_mae: 0.1109\n",
      "Epoch 6/100\n",
      "1163/1163 [==============================] - 0s 240us/step - loss: 0.0178 - mae: 0.0964 - val_loss: 0.0235 - val_mae: 0.1110\n",
      "Epoch 7/100\n",
      "1163/1163 [==============================] - 0s 222us/step - loss: 0.0151 - mae: 0.0892 - val_loss: 0.0183 - val_mae: 0.0995\n",
      "Epoch 8/100\n",
      "1163/1163 [==============================] - 0s 215us/step - loss: 0.0139 - mae: 0.0867 - val_loss: 0.0265 - val_mae: 0.1242\n",
      "Epoch 9/100\n",
      "1163/1163 [==============================] - 0s 248us/step - loss: 0.0130 - mae: 0.0828 - val_loss: 0.0325 - val_mae: 0.1375\n",
      "Epoch 10/100\n",
      "1163/1163 [==============================] - 0s 268us/step - loss: 0.0113 - mae: 0.0787 - val_loss: 0.0211 - val_mae: 0.1074\n",
      "Epoch 11/100\n",
      "1163/1163 [==============================] - 0s 265us/step - loss: 0.0116 - mae: 0.0782 - val_loss: 0.0248 - val_mae: 0.1182\n",
      "Epoch 12/100\n",
      "1163/1163 [==============================] - 0s 253us/step - loss: 0.0095 - mae: 0.0708 - val_loss: 0.0305 - val_mae: 0.1327\n",
      "Epoch 13/100\n",
      "1163/1163 [==============================] - 0s 282us/step - loss: 0.0099 - mae: 0.0720 - val_loss: 0.0189 - val_mae: 0.0984\n",
      "Epoch 14/100\n",
      "1163/1163 [==============================] - 0s 250us/step - loss: 0.0084 - mae: 0.0663 - val_loss: 0.0258 - val_mae: 0.1183\n",
      "Epoch 15/100\n",
      "1163/1163 [==============================] - 0s 247us/step - loss: 0.0086 - mae: 0.0668 - val_loss: 0.0210 - val_mae: 0.1026\n",
      "Epoch 16/100\n",
      "1163/1163 [==============================] - 0s 271us/step - loss: 0.0075 - mae: 0.0639 - val_loss: 0.0190 - val_mae: 0.1012\n",
      "Epoch 17/100\n",
      "1163/1163 [==============================] - 0s 279us/step - loss: 0.0067 - mae: 0.0601 - val_loss: 0.0204 - val_mae: 0.1043\n",
      "Epoch 18/100\n",
      "1163/1163 [==============================] - 0s 246us/step - loss: 0.0070 - mae: 0.0616 - val_loss: 0.0399 - val_mae: 0.1466\n",
      "Epoch 19/100\n",
      "1163/1163 [==============================] - 0s 274us/step - loss: 0.0065 - mae: 0.0580 - val_loss: 0.0266 - val_mae: 0.1217\n",
      "Epoch 20/100\n",
      "1163/1163 [==============================] - 0s 272us/step - loss: 0.0059 - mae: 0.0557 - val_loss: 0.0217 - val_mae: 0.1035\n",
      "Epoch 21/100\n",
      "1163/1163 [==============================] - 0s 273us/step - loss: 0.0060 - mae: 0.0557 - val_loss: 0.0188 - val_mae: 0.1000\n",
      "Epoch 22/100\n",
      "1163/1163 [==============================] - 0s 255us/step - loss: 0.0051 - mae: 0.0510 - val_loss: 0.0207 - val_mae: 0.1041\n",
      "Epoch 23/100\n",
      "1163/1163 [==============================] - 0s 296us/step - loss: 0.0055 - mae: 0.0548 - val_loss: 0.0205 - val_mae: 0.1087\n",
      "Epoch 24/100\n",
      "1163/1163 [==============================] - 0s 269us/step - loss: 0.0051 - mae: 0.0509 - val_loss: 0.0216 - val_mae: 0.1065\n",
      "Epoch 25/100\n",
      "1163/1163 [==============================] - 0s 314us/step - loss: 0.0045 - mae: 0.0482 - val_loss: 0.0204 - val_mae: 0.1021\n",
      "Epoch 26/100\n",
      "1163/1163 [==============================] - 0s 306us/step - loss: 0.0043 - mae: 0.0484 - val_loss: 0.0227 - val_mae: 0.1086\n",
      "Epoch 27/100\n",
      "1163/1163 [==============================] - 0s 288us/step - loss: 0.0045 - mae: 0.0486 - val_loss: 0.0187 - val_mae: 0.1012\n",
      "Epoch 28/100\n",
      "1163/1163 [==============================] - 0s 285us/step - loss: 0.0044 - mae: 0.0476 - val_loss: 0.0192 - val_mae: 0.1037\n",
      "Epoch 29/100\n",
      "1163/1163 [==============================] - 0s 284us/step - loss: 0.0043 - mae: 0.0472 - val_loss: 0.0206 - val_mae: 0.1017\n",
      "Epoch 30/100\n",
      "1163/1163 [==============================] - 0s 286us/step - loss: 0.0044 - mae: 0.0476 - val_loss: 0.0209 - val_mae: 0.1080\n",
      "Epoch 31/100\n",
      "1163/1163 [==============================] - 0s 312us/step - loss: 0.0033 - mae: 0.0424 - val_loss: 0.0196 - val_mae: 0.1017\n",
      "Epoch 32/100\n",
      "1163/1163 [==============================] - 0s 267us/step - loss: 0.0036 - mae: 0.0432 - val_loss: 0.0215 - val_mae: 0.1068\n",
      "Epoch 33/100\n",
      "1163/1163 [==============================] - 0s 276us/step - loss: 0.0038 - mae: 0.0435 - val_loss: 0.0237 - val_mae: 0.1120\n",
      "Epoch 34/100\n",
      "1163/1163 [==============================] - 0s 265us/step - loss: 0.0035 - mae: 0.0427 - val_loss: 0.0195 - val_mae: 0.1019\n",
      "Epoch 35/100\n",
      "1163/1163 [==============================] - 0s 263us/step - loss: 0.0031 - mae: 0.0409 - val_loss: 0.0223 - val_mae: 0.1096\n",
      "Epoch 36/100\n",
      "1163/1163 [==============================] - 0s 287us/step - loss: 0.0034 - mae: 0.0418 - val_loss: 0.0199 - val_mae: 0.0997\n",
      "Epoch 37/100\n",
      "1163/1163 [==============================] - 0s 259us/step - loss: 0.0031 - mae: 0.0395 - val_loss: 0.0187 - val_mae: 0.1024\n",
      "Epoch 38/100\n",
      "1163/1163 [==============================] - 0s 244us/step - loss: 0.0029 - mae: 0.0383 - val_loss: 0.0196 - val_mae: 0.1017\n",
      "Epoch 39/100\n",
      "1163/1163 [==============================] - 0s 259us/step - loss: 0.0031 - mae: 0.0395 - val_loss: 0.0182 - val_mae: 0.0990\n",
      "Epoch 40/100\n",
      "1163/1163 [==============================] - 0s 228us/step - loss: 0.0027 - mae: 0.0382 - val_loss: 0.0186 - val_mae: 0.0981\n",
      "Epoch 41/100\n",
      "1163/1163 [==============================] - 0s 276us/step - loss: 0.0030 - mae: 0.0390 - val_loss: 0.0189 - val_mae: 0.1003\n",
      "Epoch 42/100\n",
      "1163/1163 [==============================] - 0s 238us/step - loss: 0.0027 - mae: 0.0371 - val_loss: 0.0193 - val_mae: 0.1028\n",
      "Epoch 43/100\n",
      "1163/1163 [==============================] - 0s 268us/step - loss: 0.0027 - mae: 0.0374 - val_loss: 0.0178 - val_mae: 0.1012\n",
      "Epoch 44/100\n",
      "1163/1163 [==============================] - 0s 257us/step - loss: 0.0029 - mae: 0.0379 - val_loss: 0.0172 - val_mae: 0.0938\n",
      "Epoch 45/100\n",
      "1163/1163 [==============================] - 0s 277us/step - loss: 0.0028 - mae: 0.0371 - val_loss: 0.0205 - val_mae: 0.1004\n",
      "Epoch 46/100\n",
      "1163/1163 [==============================] - 0s 254us/step - loss: 0.0022 - mae: 0.0341 - val_loss: 0.0206 - val_mae: 0.1016\n",
      "Epoch 47/100\n",
      "1163/1163 [==============================] - 0s 252us/step - loss: 0.0025 - mae: 0.0356 - val_loss: 0.0187 - val_mae: 0.1012\n",
      "Epoch 48/100\n",
      "1163/1163 [==============================] - 0s 277us/step - loss: 0.0026 - mae: 0.0358 - val_loss: 0.0206 - val_mae: 0.1011\n",
      "Epoch 49/100\n",
      "1163/1163 [==============================] - 0s 281us/step - loss: 0.0023 - mae: 0.0337 - val_loss: 0.0194 - val_mae: 0.1046\n",
      "Epoch 50/100\n",
      "1163/1163 [==============================] - 0s 289us/step - loss: 0.0022 - mae: 0.0335 - val_loss: 0.0175 - val_mae: 0.0929\n",
      "Epoch 51/100\n",
      "1163/1163 [==============================] - 0s 256us/step - loss: 0.0023 - mae: 0.0343 - val_loss: 0.0174 - val_mae: 0.0930\n",
      "Epoch 52/100\n",
      "1163/1163 [==============================] - 0s 245us/step - loss: 0.0025 - mae: 0.0358 - val_loss: 0.0197 - val_mae: 0.0991\n",
      "Epoch 53/100\n",
      "1163/1163 [==============================] - 0s 252us/step - loss: 0.0023 - mae: 0.0339 - val_loss: 0.0192 - val_mae: 0.0983\n",
      "Epoch 54/100\n",
      "1163/1163 [==============================] - 0s 249us/step - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0183 - val_mae: 0.0974\n",
      "Epoch 55/100\n",
      "1163/1163 [==============================] - 0s 207us/step - loss: 0.0020 - mae: 0.0320 - val_loss: 0.0183 - val_mae: 0.0963\n",
      "Epoch 56/100\n",
      "1163/1163 [==============================] - 0s 260us/step - loss: 0.0020 - mae: 0.0319 - val_loss: 0.0176 - val_mae: 0.0983\n",
      "Epoch 57/100\n",
      "1163/1163 [==============================] - 0s 271us/step - loss: 0.0021 - mae: 0.0325 - val_loss: 0.0210 - val_mae: 0.1003\n",
      "Epoch 58/100\n",
      "1163/1163 [==============================] - 0s 214us/step - loss: 0.0022 - mae: 0.0317 - val_loss: 0.0177 - val_mae: 0.0979\n",
      "Epoch 59/100\n",
      "1163/1163 [==============================] - 0s 199us/step - loss: 0.0019 - mae: 0.0313 - val_loss: 0.0195 - val_mae: 0.0988\n",
      "Epoch 60/100\n",
      "1163/1163 [==============================] - 0s 209us/step - loss: 0.0018 - mae: 0.0310 - val_loss: 0.0189 - val_mae: 0.0959\n",
      "Epoch 61/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0018 - mae: 0.0304 - val_loss: 0.0179 - val_mae: 0.0949\n",
      "Epoch 62/100\n",
      "1163/1163 [==============================] - 0s 213us/step - loss: 0.0020 - mae: 0.0316 - val_loss: 0.0176 - val_mae: 0.0958\n",
      "Epoch 63/100\n",
      "1163/1163 [==============================] - 0s 237us/step - loss: 0.0018 - mae: 0.0302 - val_loss: 0.0179 - val_mae: 0.0975\n",
      "Epoch 64/100\n",
      "1163/1163 [==============================] - 0s 211us/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0179 - val_mae: 0.0971\n",
      "Epoch 65/100\n",
      "1163/1163 [==============================] - 0s 265us/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0178 - val_mae: 0.0951\n",
      "Epoch 66/100\n",
      "1163/1163 [==============================] - 0s 269us/step - loss: 0.0017 - mae: 0.0297 - val_loss: 0.0189 - val_mae: 0.0978\n",
      "Epoch 67/100\n",
      "1163/1163 [==============================] - 0s 239us/step - loss: 0.0017 - mae: 0.0290 - val_loss: 0.0195 - val_mae: 0.0998\n",
      "Epoch 68/100\n",
      "1163/1163 [==============================] - 0s 225us/step - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0192 - val_mae: 0.1022\n",
      "Epoch 69/100\n",
      "1163/1163 [==============================] - 0s 280us/step - loss: 0.0018 - mae: 0.0299 - val_loss: 0.0190 - val_mae: 0.0981\n",
      "Epoch 70/100\n",
      "1163/1163 [==============================] - 0s 260us/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0171 - val_mae: 0.0952\n",
      "Epoch 71/100\n",
      "1163/1163 [==============================] - 0s 231us/step - loss: 0.0018 - mae: 0.0294 - val_loss: 0.0181 - val_mae: 0.0967\n",
      "Epoch 72/100\n",
      "1163/1163 [==============================] - 0s 266us/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0175 - val_mae: 0.0942\n",
      "Epoch 73/100\n",
      "1163/1163 [==============================] - 0s 349us/step - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0180 - val_mae: 0.0964\n",
      "Epoch 74/100\n",
      "1163/1163 [==============================] - 0s 356us/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0186 - val_mae: 0.0985\n",
      "Epoch 75/100\n",
      "1163/1163 [==============================] - 0s 243us/step - loss: 0.0014 - mae: 0.0271 - val_loss: 0.0193 - val_mae: 0.1028\n",
      "Epoch 76/100\n",
      "1163/1163 [==============================] - 0s 338us/step - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0229 - val_mae: 0.1095\n",
      "Epoch 77/100\n",
      "1163/1163 [==============================] - 0s 254us/step - loss: 0.0015 - mae: 0.0277 - val_loss: 0.0171 - val_mae: 0.0936\n",
      "Epoch 78/100\n",
      "1163/1163 [==============================] - 0s 251us/step - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0178 - val_mae: 0.0962\n",
      "Epoch 79/100\n",
      "1163/1163 [==============================] - 0s 203us/step - loss: 0.0015 - mae: 0.0270 - val_loss: 0.0168 - val_mae: 0.0934\n",
      "Epoch 80/100\n",
      "1163/1163 [==============================] - 0s 206us/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0187 - val_mae: 0.0957\n",
      "Epoch 81/100\n",
      "1163/1163 [==============================] - 0s 204us/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0186 - val_mae: 0.0984\n",
      "Epoch 82/100\n",
      "1163/1163 [==============================] - 0s 220us/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0160 - val_mae: 0.0933\n",
      "Epoch 83/100\n",
      "1163/1163 [==============================] - 0s 208us/step - loss: 0.0014 - mae: 0.0263 - val_loss: 0.0179 - val_mae: 0.0946\n",
      "Epoch 84/100\n",
      "1163/1163 [==============================] - 0s 211us/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0175 - val_mae: 0.0945\n",
      "Epoch 85/100\n",
      "1163/1163 [==============================] - 0s 215us/step - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0180 - val_mae: 0.0986\n",
      "Epoch 86/100\n",
      "1163/1163 [==============================] - 0s 233us/step - loss: 0.0014 - mae: 0.0258 - val_loss: 0.0172 - val_mae: 0.0939\n",
      "Epoch 87/100\n",
      "1163/1163 [==============================] - 0s 209us/step - loss: 0.0013 - mae: 0.0242 - val_loss: 0.0193 - val_mae: 0.0956\n",
      "Epoch 88/100\n",
      "1163/1163 [==============================] - 0s 215us/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0167 - val_mae: 0.0935\n",
      "Epoch 89/100\n",
      "1163/1163 [==============================] - 0s 207us/step - loss: 0.0014 - mae: 0.0252 - val_loss: 0.0181 - val_mae: 0.0954\n",
      "Epoch 90/100\n",
      "1163/1163 [==============================] - 0s 273us/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0180 - val_mae: 0.0960\n",
      "Epoch 91/100\n",
      "1163/1163 [==============================] - 0s 227us/step - loss: 0.0014 - mae: 0.0258 - val_loss: 0.0195 - val_mae: 0.0977\n",
      "Epoch 92/100\n",
      "1163/1163 [==============================] - 0s 196us/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0183 - val_mae: 0.0958\n",
      "Epoch 93/100\n",
      "1163/1163 [==============================] - 0s 186us/step - loss: 0.0012 - mae: 0.0249 - val_loss: 0.0204 - val_mae: 0.1027\n",
      "Epoch 94/100\n",
      "1163/1163 [==============================] - 0s 188us/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0177 - val_mae: 0.0960\n",
      "Epoch 95/100\n",
      "1163/1163 [==============================] - 0s 206us/step - loss: 0.0013 - mae: 0.0249 - val_loss: 0.0169 - val_mae: 0.0937\n",
      "Epoch 96/100\n",
      "1163/1163 [==============================] - 0s 181us/step - loss: 0.0012 - mae: 0.0242 - val_loss: 0.0163 - val_mae: 0.0915\n",
      "Epoch 97/100\n",
      "1163/1163 [==============================] - 0s 168us/step - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0178 - val_mae: 0.0949\n",
      "Epoch 98/100\n",
      "1163/1163 [==============================] - 0s 177us/step - loss: 0.0011 - mae: 0.0240 - val_loss: 0.0180 - val_mae: 0.0955\n",
      "Epoch 99/100\n",
      "1163/1163 [==============================] - 0s 205us/step - loss: 0.0013 - mae: 0.0252 - val_loss: 0.0183 - val_mae: 0.0955\n",
      "Epoch 100/100\n",
      "1163/1163 [==============================] - 0s 219us/step - loss: 0.0012 - mae: 0.0242 - val_loss: 0.0170 - val_mae: 0.0956\n"
     ]
    }
   ],
   "source": [
    "k = 6\n",
    "num_val = len(Xtrain)//k\n",
    "all_hist = []\n",
    "for i in range(k):\n",
    "    print('processing fold #',i)\n",
    "    val_data = Xtrain[i*num_val:(i+1)*num_val]\n",
    "    val_target = Ytrain[i*num_val:(i+1)*num_val]\n",
    "    \n",
    "    partial_data = np.concatenate([Xtrain[:i*num_val],Xtrain[(i+1)*num_val:]],axis = 0)\n",
    "    partial_target = np.concatenate([Ytrain[:i*num_val],Ytrain[(i+1)*num_val:]],axis = 0)\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_data,partial_target,epochs=100,batch_size=20,verbose = 1,validation_data=(val_data,val_target))\n",
    "    model.save(\"file2.h5\")\n",
    "    mae_hist = history.history['val_mae']\n",
    "    all_hist.append(mae_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_ame_hist = [np.mean([x[i] for x in all_hist]) for i in range(100)]\n",
    "def smoothcurve(pnt,factor=0.9):\n",
    "    smoothed_pnt = []\n",
    "    for j in pnt:\n",
    "        if smoothed_pnt:\n",
    "            previous = smoothed_pnt[-1]\n",
    "            smoothed_pnt.append(previous * factor + j * (1-factor))\n",
    "        else:\n",
    "            smoothed_pnt.append(j)\n",
    "    return smoothed_pnt\n",
    "\n",
    "smoothmae_hist = smoothcurve(avg_ame_hist[10:])\n",
    "\n",
    "plt.plot(range(1,len(smoothmae_hist) + 1),smoothmae_hist)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.119408763187627"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599/599 [==============================] - 0s 75us/step\n",
      "599/599 [==============================] - 0s 402us/step\n",
      "0.109959177672863\n"
     ]
    }
   ],
   "source": [
    "test_mse,test_mae = model.evaluate(Xtest,Ytest)\n",
    "var = load_model(\"file2.h5\")\n",
    "result =var.evaluate(Xtest,Ytest)\n",
    "print(test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
